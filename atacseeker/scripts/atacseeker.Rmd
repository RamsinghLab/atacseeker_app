---
title: "ATACseq Analysis Report"
author: "ATACseeker"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: html_document
---

```{r, include = FALSE, echo = FALSE, message = FALSE, warning = FALSE}
library(knitr)
knitr::opts_chunk$set(echo = F, warning = F, message = F, comment = "")
```

```{r load_library}
## CRAN
library(locfit)
library(parallel)
library(R2HTML)
library(statmod)

## Bioconductor packages
library(csaw) 
library(edgeR)
library(Gviz)
library(Homo.sapiens)
library(LOLA) 
library(Rsamtools)
library(rtracklayer)

## Github package
library(ATACseeker)

## Helper scripts
source("atacseeker.R")
source("parse_AppSession.R")
```

```{r setup_out_scratch}
## Defining Output and Scratch directories.
test = F
app_session_name = gsub('/','-', app_session_name)
base_dir = "/data/output/appresults"
dump_dir = "/data/scratch"
if(test){
    base_dir = "/Users/asifzubair/projects/atacseq_counts/data/output/appresults"
    dump_dir = "/Users/asifzubair/projects/atacseq_counts/data/scratch"
 ##   dedup = TRUE
 ##   mapQ = 10
 ##   win.width = 150
}

output_dir = file.path(base_dir, project_id, app_session_name)
dir.create(output_dir, recursive = TRUE)
cat(paste0("cp /atacseeker/scripts/atacseeker.html", " '", output_dir, "'\n"), 
        file = "atacseeker_helper.sh", append=TRUE)  
```


```{r setup_var_input}
## Setting up Control and Compare variables and Input directory.
control.label = control
compare.label = comparison
control = controlName
compare = compareName
samples = c(control, compare)
num_control = length(control)
num_compare = length(compare)
num_samples = length(samples)

base_dir = "/data/input/appresults"
if(test){
    base_dir = "/Users/asifzubair/projects/atacseq_counts/data/input/appresults"
}

tmp <- get_bams(controlID, controlName)
control.files = tmp$group.in
tmp<- get_bams(compareID, compareName)
compare.files = tmp$group.in
bam.files = c(control.files, compare.files)
margin = max(sapply(samples, nchar))
mars = c(max(margin / 1.8, 5), 4, 4, 0.9) + 0.1
```

```{r mtDNA_analysis}
## Mitochondrial assembly
if (do_mtdNA_analysis){
    dir.create(file.path(dump_dir, "mtDNA_assembly"), recursive = TRUE)
    tmp <- mapply(dir.create, path = file.path(dump_dir, "mtDNA_assembly", samples), recursive = TRUE)

    chrM.files = file.path(dump_dir, "mtDNA_assembly", samples, paste0("chrM.",samples,".bam"))
    chrM_command = paste("samtools view -F 4 -h", bam.files, "\"chrM\" | samtools view -Sb - >", chrM.files)

    for (i in seq(num_samples)){
        cat("samtools view -F 4 -h", bam.files[i], "\"chrM\" | samtools view -Sb - >", chrM.files[i], "\n",
            file = "atacseeker_helper.sh", append = TRUE)
        cat("bash assembleMTgenome.sh", chrM.files[i], ">", 
            file.path(dump_dir, "mtDNA_assembly", samples[i], "mtDNA_analysis.log 2>&1"), "\n",
            file = "atacseeker_helper.sh", append = TRUE)
    }

    cat(paste0("mv ", file.path(dump_dir, "mtDNA_assembly"), " '", output_dir, "'\n"),
        file = "atacseeker_helper.sh", append = TRUE)
}
```

## Workflow Description ##

We work with the App Result generated by the Illumina's <a href="https://basespace.illumina.com/apps/2686684/BWA-Aligner" target="_blank"> BWA Aligner</a>. It is recommended that quality checks, including marking PCR dupes, are done using the BWA App prior to pushing the aligned bam files through the ATACseeker. 

The bam files are piped through <a href="http://bioconductor.org/packages/release/bioc/html/csaw.html" target="_blank"> csaw </a> for a two-group comparison. 

QC metrics for the aligned reads are also computed and displayed. Fragment size and window length parameters are estimated. Thereafter, the libraries are normalised and filtering of windows is done to retain only high abundance windows. Finally, differential accessibility testing is done and corrrections for multiple testing are performed. 

The design matrix used for the two-sample comparison is provided below.

```{r design}
treatment = c(rep("N", length(control)), rep("Y",length(compare)))
design <- model.matrix(~treatment) 
colnames(design) <- c("Intercept", compare.label)
rownames(design) <- samples
kable(design, caption = "Design Matrix")
```

```{r read_param}
## make sure the blacklist is for the same reference which was used for the alignment.
blacklist <- import("wgEncodeDacMapabilityConsensusExcludable.hg19.bed.gz", genome="hg19")
chroms <- paste0("chr", c(seq(22), "X", "Y"))
discard.se.param <- readParam(pe = "none", restrict = chroms, discard = blacklist, minq = mapQ, dedup = dedup)
```

## QC Metrics ##

We use <a href="https://cran.r-project.org/web/packages/preseqR/index.html" target="_blank"> preseqR </a> to estimate library complexity. Library complexity gives an idea of how many unique moelcules have been caputured. 

```{r lib_complexity}
if (compute_library_complexity){
    firstBp <- 1
    lastBp <- 249250621
    chr1_5primeCuts <- lapply(bam.files, function(BAM) 
            resize(extractReads(bam.file=BAM, region=GRanges("chr1", IRanges(firstBp, lastBp))), 1, fix="start"))

    plot_complexity <- function(fivePrimeCuts, ii){
        ests <- getEsts(fivePrimeCuts)
        plotComplexity(fivePrimeCuts, ests=ests)
        legend("bottomright", legend = samples[ii], col = "red", pch = 18)
    }

    # write all the complexity graphs for each library to file.
    pdf(file.path(dump_dir, "library_complexity.pdf"))
    for (i in seq(num_samples)){
        possibleError <- tryCatch(plot_complexity(chr1_5primeCuts[[i]], i), error=function(e) e)
        if(inherits(possibleError, "error")) next
    }

    tmp <- dev.off()
    tmp <- file.copy(file.path(dump_dir, "library_complexity.pdf"), output_dir)
} else {
    cat("\tLibrary complexity estimation was not requested")
}
```


```{r chrM_tssVsNontss}
if (do_QC){ 
    par(mfrow = c(1,2), mar = mars)

    command = paste("samtools view -F 4", bam.files, "| wc -l")
    counts = mapply(system, command = command, intern = TRUE)
    chrM_command = paste("samtools view -F 4", bam.files, "\"chrM\" | wc -l")
    chrM_counts = mapply(system, command = chrM_command, intern = TRUE)
    chrMvsOther = (strtoi(as.vector(chrM_counts))) / strtoi(as.vector(counts)) 
    names(chrMvsOther) <- samples
    ylim = 1.1*max(chrMvsOther)
    
    barplot(chrMvsOther[1:num_control], col = "blue", xlim = c(0,1), width = 1/(num_control+1), 
        main = control.label, ylab = "fraction - mtDNA reads", ylim = c(0, ylim), las=3, cex.names = 0.8)
    barplot(chrMvsOther[num_control+1:num_samples], col = "red", xlim = c(0,1), width = 1/(num_compare+1), 
        main = compare.label, ylim = c(0, ylim), las=3, cex.names = 0.8)

    proms <- promoters(Homo.sapiens, upstream=2000, downstream=2000) # for hg19
    # wincounts <- windowCounts(bam.files,  shift=4, bin=TRUE, param=discard.se.param)
    wincounts <- windowCounts(bam.files, bin=TRUE, param=discard.se.param)

    tssWindows <- queryHits(findOverlaps(wincounts, proms))
    nonTssWindows <- setdiff(seq_len(nrow(wincounts)), tssWindows)

    TSS.bamCounts <- colSums(assays(wincounts[tssWindows,])$counts)
    nonTSS.bamCounts <- colSums(assays(wincounts[nonTssWindows,])$counts)
    TSSvsNonTSS <- TSS.bamCounts / nonTSS.bamCounts # ideally > 10...
    names(TSSvsNonTSS) <- samples
    ylim = 1.1*max(TSSvsNonTSS)

    barplot(TSSvsNonTSS[1:num_control], xlim = c(0,1), width = 1/(num_control + 1), las=3, 
        col = "blue", ylab = "ratio - TSS vs Non-TSS Counts", ylim = c(0, ylim), 
        main = control.label, cex.names = 0.8)
    barplot(TSSvsNonTSS[num_control+1 : num_samples], xlim = c(0,1), width = 1/(num_compare+1), las=3, 
        col= "red", ylim = c(0, ylim), main = compare.label, cex.names = 0.8)
}
```

If the input data is __paired-end__, fragment sizes in the control and comparison samples are plotted using csaw's `getPESizes` function. Some diagnostic metrics are also shown to assess data quality.  

```{r pe_metrics, fig.width=20, fig.height=10}
if (do_QC){ 
    if(testPairedEndBam(bam.files[1])){

        # use mcmapply(), but only if we haven't already...
        if (!file.exists("controlQC.rds")) {
            controlQC <- mapply(getQC, name=control, pe.bam=control.files, SIMPLIFY=F)
            if(test)
                saveRDS(controlQC, "controlQC.rds")
        } else { 
            controlQC <- readRDS("controlQC.rds")
        }

        if (!file.exists("compareQC.rds")) {
            compareQC <- mapply(getQC, name=compare, pe.bam=compare.files, SIMPLIFY=F)
            if(test)
                saveRDS(compareQC, file="compareQC.rds")  
        } else { 
            compareQC <- readRDS("compareQC.rds")
        }

        # side by side 
        par(mfrow=c(1,2))

        # plot fragment sizes for control samples
        frag.dists.control <- lapply(controlQC, `[[`, "frag.dist")
        qcPlot(frag.dists.control, control.label)

        # plot fragment sizes for comparison samples
        frag.dists.compare <- lapply(compareQC, `[[`, "frag.dist")
        qcPlot(frag.dists.compare, compare.label)

        # now dump a diagnostic table 
        combinedQC <- append(controlQC, compareQC)
        readqc <- as.data.frame(do.call(rbind, lapply(combinedQC, `[[`, "qc")))
        colnames(readqc) <- c("Sample", "Total Reads", "Mapped Reads", "Single Read", 
            "Mate Unmapped", "Unoriented", "Inter Chromosomal", "Frag. Size > 400 bp")
        kable(readqc, caption="Quality metrics for PE reads", row.names=FALSE)
    }
}
```

<!-- TODO: Add description for cross correlation plot -->

```{r cross_corr}
if (do_QC){ 
    # one plot-per-window
    par(mfrow=c(1,1))

    max.delay <- 400
    x <- correlateReads(bam.files, max.delay, param=discard.se.param)
    plot(0:max.delay, x, type="l", ylab="CCF", xlab="Delay (bp)")
    title("Cross Correlation Plot")
}
```

Coverage plot for choosing window size:

```{r cov_plot}
if (do_QC){ 
    collected <- list()

    ## Should parallelize ? 
    for (curbam in bam.files) {
    ##    windowed <- windowCounts(curbam, spacing=150, width=150, param=discard.se.param, filter=20, ext=1)
    ##    windowed <- windowCounts(curbam, ext=0, shift=4, bin=TRUE, param=discard.se.param)
        windowed <- windowCounts(curbam, spacing=150, width=150, param=discard.se.param, filter=20, ext=NA)
        rwsms <- rowSums(assay(windowed))
        maxed <- findMaxima(rowRanges(windowed), range=1000, metric=rwsms)
        collected[[curbam]] <- profileSites(curbam, rowRanges(windowed)[maxed], 
            param=discard.se.param, weight=1/rwsms[maxed])
    }

    xranged <- as.integer(names(collected[[1]]))
    for (i in seq(length(samples))){
        if (i==1)
            plot(xranged, collected[[i]], type="l", col=i, lwd=1,
                xlim=c(-1000, 1000), ylim=c(0, 1.0), 
                xlab="Distance (bp)", ylab="Relative coverage per base")
        else
            lines(xranged, collected[[i]], col=i, lwd=1)
    }

    legend("topright", col=seq(length(samples)), samples, pch=16)
    title("Coverage Profile")
    abline(v=c(-win.width, win.width), col="gray", lty=3, lwd=4)
}
```

```{r mem_clean_up_one}
if (do_QC){
    rm(list = c("chr1_5primeCuts", "collected", "combinedQC", "compareQC", "controlQC", "maxed", "x", 
    "nonTSS.bamCounts", "nonTssWindows", "rwsms", "TSS.bamCounts", "tssWindows", "wincounts", "windowed"))
}
cleanMem()
collectGarbage()
```

## CSAW Parameters ##

Read extraction parameters:

```{r read_extraction}
discard.se.param
window.width <- win.width
data <- windowCounts(bam.files, width = window.width, param = discard.se.param, ext = 1)
binned <- windowCounts(bam.files, bin = TRUE, width = 1000, param = discard.se.param)
cat(paste("\tWindow width for counting reads is", window.width))

collectGarbage()
```

```{r mem_clean_up_two}
cleanMem()
collectGarbage()
```

## Filtering ##

Keep only high abundance regions relative to a  global background.

```{r filter_global}
filter.stat <- filterWindows(data, background = binned, type = "global")
keep <- filter.stat$filter > log2(3)

hist(filter.stat$back.abundances, xlab = "Adjusted bin log-CPM", breaks = 50, main = "")
# xlim=c(min(filter.stat$back.abundances), 0))
global.bg <- filter.stat$abundances - filter.stat$filter
abline(v=global.bg[1], col = "red", lwd = 2)
abline(v=global.bg[1]+log2(3), col = "blue", lwd = 2)
legend("topright", lwd=2, col=c('red', 'blue'), legend=c("Background", "Threshold"))

raw = colSums(assays(data)$counts)
filtered.data <- data[keep,]
filtered = colSums(assays(filtered.data)$counts)

par(mar = mars)
m = as.matrix(rbind(raw, filtered))
colnames(m) = samples
barplot(m, beside=TRUE, col = c(rep("blue", 2*length(control)), rep("red", 2*length(compare))), 
    cex.names = 0.8, width = 1/(2*num_samples + 1), las = 3,
    main = "Window counts")
barplot(m, add = T, beside = T, col = 1, angle = 45, density = c(0,15), 
    cex.names = 0.8, width = 1/(2*num_samples + 1), las = 3)
legend("topright", legend = "filtered", fill = T, angle = 45, density = 15, bty = "n", cex = 1.25)
```

## Normalization ##

We account for composition bias.

```{r normalization}
par(mar = mars)
Norm.factors <- normOffsets(binned)
ylim = 1.1*max(as.vector(Norm.factors))
barplot(as.vector(Norm.factors), names.arg = samples, main = "Normalizing factors", 
    col = c(rep("blue", length(control)), rep("red",length(compare))), 
    cex.names = 0.8, width = 1/(num_samples + 1), las = 3, ylim = c(0,ylim))
```

## Differential Accessibility Testing ##

Let's see how the samples are clustered:

```{r cluster}
## binned.2 <- windowCounts(bam.files, bin=TRUE, width=1000, param=pe.param)
bin.adjc <- cpm(asDGEList(binned), log = T)
color = c(rep("blue", length(control)), rep("red",length(compare)))
plotMDS(bin.adjc, labels = samples, col = color)
```

```{r est_disp, echo=FALSE}
y <- asDGEList(filtered.data, norm.factors = Norm.factors)
y <- estimateDisp(y, design)

par(mfrow=c(1,2))
o <- order(y$AveLogCPM)
plot(y$AveLogCPM[o], sqrt(y$trended.dispersion[o]), type = "l", lwd = 2,
     ylim = c(0,2), xlab = "Average log2 CPM", ylab = ("Biological coefficient of variation"))

fit <- glmQLFit(y, design, robust = T)
plotQLDisp(fit)

results <- glmQLFTest(fit, contrast = c(0,1))
kable(as.data.frame(topTags(results)), caption = "Top Tags", row.names = FALSE)
```

### Region-Level Analysis ###

Closely clustered windows are merged together to generate region-level FDR. 

The distribution of region widths post-merging:
```{r multiple_test}
merged <- mergeWindows(rowRanges(filtered.data), tol = 100, max.width = 5000)
## kable(merged$region, caption="Merged regions")
summary(width(merged$region))
tabcom <- combineTests(merged$id, results$table)
kable(head(tabcom), caption = "Combined Tests")
tabbest <- getBestTest(merged$id, results$table)
```

### Results ###

The following gives the number of significantly differentially accessible regions:
```{r results}
# annotated:
# is.sig <- tabcom$FDR <= 0.05
anno <- detailRanges(merged$region, txdb = Homo.sapiens, orgdb = Homo.sapiens)
combined <- data.frame(as.data.frame(merged$region)[,1:3], tabcom,
                       best.pos = mid(ranges(rowRanges(filtered.data[tabbest$best]))), 
                       best.logFC = tabbest$logFC,  anno)
accRanges <- makeGRangesFromDataFrame(combined, keep = T)

is.sig <- accRanges$FDR <= fdr.cut.off
diffAccRanges <- accRanges[is.sig] 
summary(is.sig)
cat(paste(sum(diffAccRanges$logFC.up > 0), "regions had logFC UP windows and", 
    sum(diffAccRanges$logFC.down > 0), "regions had logFC DOWN windows."))

# -log10(p) as bed file "score", could also export to bigWig
score(diffAccRanges) <- -1 * log10(diffAccRanges$PValue)
```

We visualize the most significantly differentially accessible region. The region details are also output.
```{r plot_region}
accessByScore <- diffAccRanges[rev(order(diffAccRanges$score))]
if (sum(is.sig) > 0)
    kable(as.data.frame(accessByScore[1]))
if (sum(is.sig) > 0){
    plotRegion(accessByScore[1])
} else {
    cat("\tNo significant regions found. Skipping plotting tracks")
}
```

Regions containing windows which are more accessible are written in `diffAccRegions.logFC.UP.html` and those with less accessible windows are in `diffAccRegions.logFC.DOWN.html` in the output folder.  Corresponding `bed` files containing differentially accessible regions has also been written to the output folder. The score column of the `bed` file indicates the negative-log of the p-value.

A raw text file, `diffAccRegions.tsv`, with all differentially accessible regions is also written to output folder. The columns in the file are described below:

|Column Name | Description |
|:-----------|:-------------|
|seqnames    | chromosome name |
|start       | start point of region |
|end         | end point of region |
|width       | region width  |
|strand      | strand  |
|nWindows    | number of windows that were clustered |
|logFC.up    |  number of windows with logFC increase compared to control |
|logFC.down  | number of windows with logFC decrease compared to control  |
|PValue      | signifance p-value  |
|FDR         | FDR correction for mutliple testing|
|best.pos    | mid-point of most significant window in region |
|best.logFC  | logFC of the most significant window |
|overlap     | gene feature that overlaps with the region |
|left        | gene feature to the left of the region |
|right       | gene feature to the right of the region |
|score       | negative log of the significance p-value |

The annotation is performed using the `detailRanges` function of `csaw`. The function identifies all overlapping genic features for each region and reports them in a string form. The features are reported as `SYMBOL|EXONS|STRAND` where  

* `SYMBOL` represents the gene symbol
* `EXON` lists the overlapping exons (`0` for promoters, `I` for introns)
* `STRAND` reports the strand  

Features in flanking regions of the region of interest are also reported. These features are formatted with the same scheme as above except with an extra `[DISTANCE]` field, which represents the distance between the feature and the region of interest. Only those flanking features which are within 5kbp of each region are considered.

```{r mem_clean_up_three}
rm(list = setdiff(ls(),
    c("test", "dump_dir", "output_dir", "dedup", "bam.files", "cleanMem", "collectGarbage",
    "compute_library_complexity", "generate_BigWigs", "do_motif_analysis", "data", "binned", 
    "y", "is.sig", "diffAccRanges")))
cleanMem()
collectGarbage()
```

```{r export_files}
# Output sites as a BED file (post-FDR-correction) 
export(diffAccRanges[diffAccRanges$logFC.up > 0,], file.path(dump_dir, "diffAccRanges.logFC.UP.hg19.bed"))
export(diffAccRanges[diffAccRanges$logFC.down > 0,], file.path(dump_dir, "diffAccRanges.logFC.DOWN.hg19.bed"))

# print out the significant (FDR <= fdr.cut.off) results 
# kable(as(diffAccRanges, "data.frame"), caption="Significant Results")
if (sum(diffAccRanges$logFC.up > 0) > 0)
    HTML(as(diffAccRanges[diffAccRanges$logFC.up > 0,], "data.frame"), 
        file=file.path(dump_dir, "diffAccRegions.logFC.UP.html"))
if (sum(diffAccRanges$logFC.down > 0) > 0)
    HTML(as(diffAccRanges[diffAccRanges$logFC.down > 0,], "data.frame"), 
        file=file.path(dump_dir, "diffAccRegions.logFC.DOWN.html"))
write.table(as(diffAccRanges, "data.frame"), file.path(dump_dir, "diffAccRegions.tsv"), row.names=FALSE, sep="\t")

save(file=file.path(dump_dir, "csaw_edgeR_objects.Rda"), data, binned, y)

cat(paste0("mv ", file.path(dump_dir, "diffAccRanges.logFC.*.hg19.bed"), " '", output_dir, "'\n"), 
    file = "atacseeker_helper.sh", append=TRUE)
cat(paste0("mv ", file.path(dump_dir, "diffAccRegions.logFC.*.html"), " '", output_dir, "'\n"), 
    file = "atacseeker_helper.sh", append = TRUE)
cat(paste0("mv ", file.path(dump_dir, "diffAccRegions.tsv"), " '", output_dir, "'\n"), 
    file = "atacseeker_helper.sh", append = TRUE)
cat(paste0("mv ", file.path(dump_dir, "csaw_edgeR_objects.Rda"), " '", output_dir, "'\n"), 
    file = "atacseeker_helper.sh", append = TRUE)    
```

```{r mem_clean_up_four}
rm(list=setdiff(ls(),
    c("test", "dump_dir", "output_dir", "dedup", "bam.files", "cleanMem", "collectGarbage",
    "compute_library_complexity", "generate_BigWigs", "do_motif_analysis", "is.sig", 
    "diffAccRanges")))
cleanMem()
collectGarbage()
```

In addition, if requested, we also output the the coverage of the `bam` files in bigwig format. These along with the above `bed` file can be used for visualisation in the <a href="https://basespace.illumina.com/apps/1886885/Integrative-Genomics-Viewer" target="_blank"> IGV </a> browser. 

```{r make_bw}
## Generate BigWig files
if (generate_BigWigs){
    dir.create(file.path(dump_dir, "BigWigs"), recursive = TRUE)

    if (dedup){
        cat("parallel -j4 bash bamToBigWig.sh {1} dedup :::", bam.files, "\n",
            file = "atacseeker_helper.sh", append = TRUE)
    } else {
        cat("parallel -j4 bash bamToBigWig.sh {1} :::", bam.files, "\n",
            file = "atacseeker_helper.sh", append = TRUE)
    }

    cat("mv", file.path(dump_dir,"*.bw"), file.path(dump_dir, "BigWigs"), "\n",
        file = "atacseeker_helper.sh", append = TRUE)
    cat(paste0("mv ", file.path(dump_dir, "BigWigs"), " '", output_dir, "'\n"),
        file = "atacseeker_helper.sh", append = TRUE)
} else {
    cat("\tBigWig files were not requested")   
}
```

<!-- TODO: implement LOLA -->

```{r lola, eval=FALSE}
# NOTE: This chunk is NOT evaluated.
# run LOLA? Yes!
dbPath <- system.file("extdata", "hg19", package="LOLA")
regionDB <- loadRegionDB(dbPath)
data("sample_input", package="LOLA") # load userSets
data("sample_universe", package="LOLA") # load userUniverse
if (FALSE) show(userUniverse)
locResults <- runLOLA(diffAccRanges, userUniverse, regionDB, cores=1)
kable(locResults[order(qValue),]) # this is just a demo, fix for app
if(FALSE) {
  # for later
  CTCFsites <- import("ubiquitousCTCFsites.hg19.bed")
  repeatRegions <- import("repeatmasker.hg19.bed")

  # FIXME: use erma for this 
  hspcChromHMM <- import("CD34.chromImpute.hg19.bed")
}
```

## Motif Enrichment ##

```{r pwm}
# Motif enrichment (PWM-based, will re-use this for differential ChIP-seq app)
if (do_motif_analysis){ 
    if (sum(is.sig) > 0){
        library(PWMEnrich)
        library(PWMEnrich.Hsapiens.background)
        library(BSgenome.Hsapiens.UCSC.hg19)
        if (TRUE){
            registerCoresPWMEnrich(2)
            useBigMemoryPWMEnrich(TRUE)
        }
        data(PWMLogn.hg19.MotifDb.Hsap)
        seqs <- getSeq(Hsapiens, diffAccRanges)
        res <- motifEnrichment(seqs, PWMLogn.hg19.MotifDb.Hsap)

        saveRDS(res, file=file.path(dump_dir,"motifEnrichment.hg19.rds"))
        tmp <- file.copy(file.path(dump_dir, "motifEnrichment.hg19.rds"), output_dir)

        # Top 10 motifs by enrichment
        kable(head(motifRankingForGroup(res), 10))
    } else {
        cat("\tNo significant regions found. Skipping Motif Enrichment Analysis")
    }
} else {
    cat("\tMotif Enrichment Analysis was not requested")
}
```

## Session Info ##

```{r sess_info}
# Dump session info for versioning, debugging, CITATIONS (!), etc.
sessionInfo()
```

## References ##
```{r references}
# Explicitly remind user: cite us and/or the various components of the pipeline!
message("Please do not forget to appropriately cite this work.")
citation("ATACseeker")
if (compute_library_complexity)
    citation("preseqR")
citation("csaw")
if (do_motif_analysis)
    citation("PWMEnrich")
## citation("LOLA")
```
