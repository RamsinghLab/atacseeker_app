---
title: "ATACseq Analysis Report"
author: "ATACseeker"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: html_document
---


```{r, message=FALSE, warning=FALSE, echo=FALSE}
## CRAN
library(statmod)
library(locfit)
library(knitr)
library(parallel)

## Bioconductor packages
library(csaw) 
library(edgeR)
library(rtracklayer)
library(Rsamtools)
library(Homo.sapiens)
library(LOLA) 
```


```{r, message=FALSE, warning=FALSE, echo=FALSE}
test = TRUE

source("parse_AppSession.R")

app_session_name = gsub('/','-', app_session_name)

base_dir = "/data/output/appresults"

if (test){
    base_dir = "/Users/asifzubair/projects/atacseq_counts/nativeApp/data/output/appresults"
    }

output_dir = file.path(base_dir, project_id, app_session_name)

cmd1 = paste0("mkdir -p ", "'", output_dir, "'")
system(cmd1)

if (!test){
    
    cmd2 = paste0("echo cp /atacseeker/scripts/atacseeker.html \\''", output_dir, "'\\' >> /atacseeker/scripts/atacseeker.sh")
    system(cmd2)
    
}

```


## Workflow Description ##

We work with the App Result generated by the Illumina BWA App. It is recommended that quality checks, including PCR dupes, is done using the BWA App prior to pushing the aligned bam files through the ATACseq App. 

The bam files are piped through [csaw](http://bioconductor.org/packages/release/bioc/html/csaw.html) for a two-group comparison. 

QC metrics for the aligned reads are also computed and displayed. Fragment size and window length parameters are estimated. Thereafter, the libraries are normalised and filtering of windows is done to retain only high abundance windows. Finally, differential accessibility testing is done and corrrections for multiple testing are performed. 


```{r, echo = FALSE}
control.label = control
compare.label = comparison

control = controlName
compare = compareName


base_dir = "/data/input/appresults"
dump_dir = "/data/scratch"

if(test){
    base_dir = "/Users/asifzubair/projects/atacseq_counts/nativeApp/data/input/appresults"
    dump_dir = "/Users/asifzubair/projects/atacseq_counts/nativeApp/data/scratch"
}


control.files = c()
for (f in seq(length(controlName))){
    
    fastq_dir = file.path(base_dir, controlID[f])
    
    bam.tmp = list.files(fastq_dir, "*bam$", full.names = TRUE)
    bam.dmp = file.path(dump_dir, basename(bam.tmp))

    if (!test){
        system(paste("cp", bam.tmp, dump_dir))
        system(paste("samtools index", bam.dmp))
        }
    
    control.files = c(control.files, bam.dmp)
    
    }

compare.files = c()
for (f in seq(length(compareName))){
    
    fastq_dir = file.path(base_dir, compareID[f])
    
    bam.tmp = list.files(fastq_dir, "*bam$", full.names = TRUE)
    bam.dmp = file.path(dump_dir, basename(bam.tmp))
    
    if (!test){
        system(paste("cp", bam.tmp, dump_dir))
        system(paste("samtools index", bam.dmp))
        }

    compare.files = c(compare.files, bam.dmp)
    
    }

samples = c(control, compare)
bam.files = c(control.files, compare.files)
```

The design matrix used for the two-sample comparison is provided below.

```{r, echo=FALSE}
treatment = c(rep("N", length(control)), rep("Y",length(compare)))

design <- model.matrix(~treatment) 
colnames(design) <- c("Intercept", compare.label)
rownames(design) <- samples

kable(design, caption = "Design Matrix")
```

## QC Metrics ##

```{r, echo=FALSE, message=FALSE, warning=FALSE}
blacklist <- import("wgEncodeDacMapabilityConsensusExcludable.hg19.bed.gz", genome="hg19")
chroms <- paste0("chr", c(seq(22), "X", "Y"))

discard.se.param <- readParam(pe = "none", restrict = chroms, discard = blacklist, minq = 10, dedup = TRUE)
```

```{r, echo=FALSE}
proms <- promoters(Homo.sapiens, upstream=2000, downstream=2000) # for hg19

wincounts <- windowCounts(bam.files,  shift=4, bin=TRUE, param=discard.se.param)
tssWindows <- queryHits(findOverlaps(wincounts, proms))
nonTssWindows <- setdiff(seq_len(nrow(wincounts)), tssWindows)

TSS.bamCounts <- colSums(assays(wincounts[tssWindows,])$counts)
nonTSS.bamCounts <- colSums(assays(wincounts[nonTssWindows,])$counts)
TSSvsNonTSS <- TSS.bamCounts / nonTSS.bamCounts # ideally > 10...
names(TSSvsNonTSS) <- samples
barplot(TSSvsNonTSS, xlim = c(0,1), width = 0.1, las=3, main="TSS vs Non-TSS Counts")
```

If the input data is **paired-end**, fragment sizes in the control and comparison samples are plotted using csaw's `getPESizes` function. Some diagnostic metrics are also shown to assess data quality.  

```{r, echo=FALSE, fig.width=20, fig.height=10}
source("atacseeker.R")

if(testPairedEndBam(bam.files[1])){

    # use mcmapply(), but only if we haven't already...
    if (!file.exists("controlQC.rds")) {
        controlQC <- mcmapply(getQC, name=control, pe.bam=control.files, SIMPLIFY=F)
        saveRDS(controlQC, "controlQC.rds")
    } else { 
        controlQC <- readRDS("controlQC.rds")
    }
    if (!file.exists("compareQC.rds")) {
        compareQC <- mcmapply(getQC, name=compare, pe.bam=compare.files, SIMPLIFY=F)
        saveRDS(compareQC, file="compareQC.rds")  
    } else { 
        compareQC <- readRDS("compareQC.rds")
    }


    # side by side 
    par(mfrow=c(1,2))

    # plot fragment sizes for control samples
    frag.dists.control <- lapply(controlQC, `[[`, "frag.dist")
    qcPlot(frag.dists.control, control.label)

    # plot fragment sizes for comparison samples
    frag.dists.compare <- lapply(compareQC, `[[`, "frag.dist")
    qcPlot(frag.dists.compare, compare.label)

    # now dump a diagnostic table 
    combinedQC <- append(controlQC, compareQC)
    readqc <- as.data.frame(do.call(rbind, lapply(combinedQC, `[[`, "qc")))
    colnames(readqc) <- c("Sample", "Total Reads", "Mapped Reads", "Single Read", "Mate Unmapped", "Unoriented", "Inter Chromosomal", "Frag. Size > 400 bp")
    kable(readqc, caption="Quality metrics for PE reads")

}

```


<!-- TODO: Add description for cross correlation plot -->


```{r, echo=FALSE}

# one plot-per-window
 par(mfrow=c(1,1))

max.delay <- 400
x <- correlateReads(bam.files, max.delay, param=discard.se.param)
plot(0:max.delay, x, type="l", ylab="CCF", xlab="Delay (bp)")
title("Cross Correlation Plot")
```


Coverage plot for choosing window size:


```{r, echo=FALSE}
collected <- list()

## Should parallelize ? 
for (curbam in bam.files) {
    windowed <- windowCounts(curbam, spacing=150, width=150, param=discard.se.param, filter=20, ext=1)
##    windowed <- windowCounts(curbam, ext=0, shift=4, bin=TRUE, param=discard.se.param)
    rwsms <- rowSums(assay(windowed))
    maxed <- findMaxima(rowRanges(windowed), range=1000, metric=rwsms)
    collected[[curbam]] <- profileSites(curbam, rowRanges(windowed)[maxed],
                                        param=discard.se.param, weight=1/rwsms[maxed])
}

xranged <- as.integer(names(collected[[1]]))

for (i in seq(length(samples))){
  if (i ==1)
    plot(xranged, collected[[i]], type="l", col=i, lwd=1,
     xlim=c(-1000, 1000), ylim=c(0, 1.0), 
     xlab="Distance (bp)", ylab="Relative coverage per base")
  else
    lines(xranged, collected[[i]], col=i, lwd=1)
}

legend("topright", col=seq(length(samples)), samples, pch=16)
title("Coverage Profile")
abline(v=c(-150,150), col="gray", lty=3, lwd=4)
```


## Windowed read counts, Filtering, Normalization ##

Read extraction parameters:

```{r, echo=FALSE, comment=""}
discard.se.param
window.width <- 150
data <- windowCounts(bam.files, width = window.width, param = discard.se.param, ext=NA)
kable(as.data.frame(data$totals, row.name=samples), caption="Total number of reads in each library")
binned <- windowCounts(bam.files, bin=TRUE, width=1000, param=discard.se.param)
```

Keep only high abundance regions relative to a  global background.

```{r, echo=FALSE}
filter.stat <- filterWindows(data, background=binned, type="global")
keep <- filter.stat$filter > log2(3)

hist(filter.stat$back.abundances, xlab="Adjusted bin log-CPM", breaks=100, 
     main="", xlim=c(min(filter.stat$back.abundances), 0))
global.bg <- filter.stat$abundances - filter.stat$filter
abline(v=global.bg[1], col="red", lwd=2)
abline(v=global.bg[1]+log2(3), col="blue", lwd=2)
legend("topright", lwd=2, col=c('red', 'blue'), legend=c("Background", "Threshold"))

filtered.data <- data[keep,]
kable(as.data.frame(filtered.data$totals, row.name=samples), caption="Total number of reads post filtering.")
```


```{r, echo=FALSE}
Norm.factors <- normOffsets(binned)
kable(as.data.frame(Norm.factors, row.names=samples), caption="Normalizing factors")
```

## Differential Accessibility Testing ##

Let's see how the samples are clustered:

```{r, echo=FALSE}
## binned.2 <- windowCounts(bam.files, bin=TRUE, width=1000, param=pe.param)
bin.adjc <- cpm(asDGEList(binned), log=TRUE)
plotMDS(bin.adjc, labels=samples)
```


```{r, echo=FALSE}
y <- asDGEList(filtered.data, norm.factors=Norm.factors)
y <- estimateDisp(y, design)

par(mfrow=c(1,2))
o <- order(y$AveLogCPM)
plot(y$AveLogCPM[o], sqrt(y$trended.dispersion[o]), type="l", lwd=2,
     ylim=c(0,1), xlab="Average log2 CPM", ylab=("Biological coefficient of variation"))

fit <- glmQLFit(y, design, robust=TRUE)
plotQLDisp(fit)

results <- glmQLFTest(fit, contrast=c(0,1))
kable(topTags(results), caption="Top Tags")
```

### Multiple Testing Correction ###

```{r, echo=FALSE}
merged <- mergeWindows(rowRanges(filtered.data), tol=1000L)
## kable(merged$region, caption="Merged regions")
```


```{r, echo=FALSE}
tabcom <- combineTests(merged$id, results$table)
kable(head(tabcom), caption="Combined Tests")
## kable(summary(width(merged$region)))
```


### Results ###


```{r, echo=FALSE}
# annotated:
is.sig <- tabcom$FDR <= 0.05
anno <- detailRanges(merged$region, txdb=Homo.sapiens, orgdb=Homo.sapiens)
combined <- data.frame(as.data.frame(merged$region)[,1:3], tabcom, anno)
accRanges <- makeGRangesFromDataFrame(combined, keep=TRUE)
diffAccRanges <- accRanges[accRanges$FDR <= 0.1] 

# export to a BED file
# library(rtracklayer)

# -log10(p) as bed file "score", could also export to bigWig
score(diffAccRanges) <- -1 * log10(diffAccRanges$PValue)

# Output sites as a BED file (post-FDR-correction, chop at 0.1 or 0.01?) 
export(diffAccRanges, "diffAccRanges.NS.fdrLt01.hg19.bed")

if (!test){
    cmd3 = paste0("echo cp /atacseeker/scripts/diffAccRanges.NS.fdrLt01.hg19.bed \\''", output_dir, "'\\' >> /atacseeker/scripts/atacseeker.sh")
    system(cmd3)
}

# print out the significant (FDR <= 0.1) results 
kable(as(diffAccRanges, "data.frame"), caption="Significant Results")
```


## LOLA ##

```{r, eval=FALSE, echo=FALSE}
# run LOLA? Yes!
dbPath <- system.file("extdata", "hg19", package="LOLA")
regionDB <- loadRegionDB(dbPath)
data("sample_input", package="LOLA") # load userSets
data("sample_universe", package="LOLA") # load userUniverse
if (FALSE) show(userUniverse)
locResults <- runLOLA(diffAccRanges, userUniverse, regionDB, cores=1)
kable(locResults[order(qValue),]) # this is just a demo, fix for app

if(FALSE) {

  # for later
  library(rtracklayer)
  CTCFsites <- import("ubiquitousCTCFsites.hg19.bed")
  repeatRegions <- import("repeatmasker.hg19.bed")

  # FIXME: use erma for this 
  hspcChromHMM <- import("CD34.chromImpute.hg19.bed")
}

# Motif enrichment (PWM-based, will re-use this for differential ChIP-seq app)
library(PWMEnrich)
library(PWMEnrich.Hsapiens.background)
library(BSgenome.Hsapiens.UCSC.hg19)
data(PWMLogn.hg19.MotifDb.Hsap)
seqs <- getSeq(Hsapiens, diffAccRanges)
res <- motifEnrichment(seqs, PWMLogn.hg19.MotifDb.Hsap)
saveRDS(res, file="motifEnrichmentNS.hg19.rds")

# Top 10 motifs by enrichment
kable(head(motifRankingForGroup(res), 10))
```


## Session Info ##

```{r, echo=FALSE, comment=""}
# Dump session info for versioning, debugging, CITATIONS (!), etc.
sessionInfo()

# Explicitly remind user: cite us and/or the various components of the pipeline!
message("Please do not forget to appropriately cite this work.")
## citation("ATACseekeR")
citation("csaw")
## citation("PWMEnrich")
citation("LOLA")
```



