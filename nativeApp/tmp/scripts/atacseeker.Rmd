---
title: "ATACseq Analysis Report"
author: "ATACseeker"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: html_document
---


```{r, message=FALSE, warning=FALSE, echo=FALSE}
library(csaw) 
library(edgeR)
library(statmod)
library(locfit)
library(knitr)
library(parallel)
library(rtracklayer)
```


```{r, message=FALSE, warning=FALSE, echo=FALSE}
source("parse_AppSession.R")

app_session_name = gsub('/','-', app_session_name)

## base_dir = "/data/output/appresults"
base_dir = "/Users/asifzubair/projects/atacseq_counts/nativeApp/data/output/appresults"

output_dir = file.path(base_dir, project_id, app_session_name)

cmd1 = paste0("mkdir -p ", "'", output_dir, "'")
system(cmd1)

## cmd2 = paste0("echo cp /atacseeker/scripts/atacseeker.html \\''", output_dir, "'\\' >> /atacseeker/scripts/atacseeker.sh")
## system(cmd2)
```


## Workflow Description ##

We work with the App Result generated by the Illumina BWA App. It is recommended that quality checks, including PCR dupes, is done using the BWA App prior to pushing the aligned bam files through the ATACseq App. 

The bam files are piped through [csaw](http://bioconductor.org/packages/release/bioc/html/csaw.html) for a two-group comparison. 

QC metrics for the aligned reads are also computed and displayed. Fragment size and window length parameters are estimated. Thereafter, the libraries are normalised and filtering of windows is done to retain only high abundance windows. Finally, differential accessibility testing is done and corrrections for multiple testing are performed. 


```{r, echo = FALSE}
control.label = control
compare.label = comparison

control = controlName
compare = compareName

## base_dir = "/data/input/appresults"
## dump_dir = "/data/scratch"

base_dir = "/Users/asifzubair/projects/atacseq_counts/nativeApp/data/input/appresults"
dump_dir = "/Users/asifzubair/projects/atacseq_counts/nativeApp/data/scratch"

control.files = c()
for (f in seq(length(controlName))){
  
  fastq_dir = file.path(base_dir, controlID[f])
  ## control.files = c(control.files, file.path(fastq_dir, paste0(controlName[f], ".bam")))
  control.files = c(control.files, list.files(file.path(base_dir, controlID[f]), "*bam$", full.names = TRUE))
  
  }

compare.files = c()
for (f in seq(length(compareName))){
  
  fastq_dir = file.path(base_dir, compareID[f])
  ## compare.files = c(compare.files, file.path(fastq_dir, paste0(compareName[f], ".bam")))
  compare.files = c(compare.files, list.files(file.path(base_dir, compareID[f]), "*bam$", full.names = TRUE))
  }

samples = c(control, compare)
bam.files = c(control.files, compare.files)
```

The design matrix used for the two-sample comparison is provided below.

```{r, echo=FALSE}
treatment = c(rep("N", length(control)), rep("Y",length(compare)))

design <- model.matrix(~treatment) 
colnames(design) <- c("Intercept", compare.label)
rownames(design) <- samples

kable(design, caption = "Design Matrix")
```

## QC Metrics ##

```{r, echo=FALSE, message=FALSE, warning=FALSE}
## frag.len <- 150
blacklist <- import("wgEncodeDacMapabilityConsensusExcludable.hg19.bed.gz", genome="hg19")
chroms <- paste0("chr", c(seq(22), "X", "Y"))

## Do we use the minq=50 parameter ?

## Define parameters for read extraction
## pe.first <- readParam(pe = "first", dedup = TRUE)
## pe.param <- readParam(pe = "both", max.frag = frag.len, dedup=TRUE)
discard.se.param <- readParam(pe = "none", restrict = chroms, discard = blacklist, dedup = TRUE)
## fast.param <- reform(discard.param, fast.pe = TRUE)

## Dump all paired end reads into /data/scratch
## bam.dmp.files <- mcmapply(dumpPE, bam.file=bam.files, prefix=file.path(dump_dir, samples), param = discard.param, overwrite=FALSE)
## bam.dmp.files <- as.vector(bam.dmp.files)
```

Fragment sizes in the control and comparison samples are plotted using csaw's `getPESizes` function. 

```{r, echo=FALSE, fig.width=20, fig.height=10}
source("atacseeker.R")

# use mcmapply(), but only if we haven't already...
if (!file.exists("controlQC.rds")) {
  controlQC <- mcmapply(getQC, name=control, pe.bam=control.files, SIMPLIFY=F)
  saveRDS(controlQC, "controlQC.rds")
} else { 
  controlQC <- readRDS("controlQC.rds")
}
if (!file.exists("compareQC.rds")) {
  compareQC <- mcmapply(getQC, name=compare, pe.bam=compare.files, SIMPLIFY=F)
  saveRDS(compareQC, file="compareQC.rds")  
} else { 
  compareQC <- readRDS("compareQC.rds")
}

# side by side 
par(mfrow=c(1,2))

# plot fragment sizes for control samples
frag.dists.control <- lapply(controlQC, `[[`, "frag.dist")
qcPlot(frag.dists.control, control.label)

# plot fragment sizes for comparison samples
frag.dists.compare <- lapply(compareQC, `[[`, "frag.dist")
qcPlot(frag.dists.compare, compare.label)

# now dump a diagnostic table 
combinedQC <- append(controlQC, compareQC)
readqc <- as.data.frame(do.call(rbind, lapply(combinedQC, `[[`, "qc")))
colnames(readqc) <- c("Sample", "Total Reads", "Mapped Reads", "Single Read", "Mate Unmapped", "Unoriented", "Inter Chromosomal", "Frag. Size > 400 bp")
kable(readqc, caption="Quality metrics for PE reads")

# one plot-per-window
# par(mfrow=c(1,1))
```


<!-- TODO: Add description for cross correlation plot -->


```{r, echo=FALSE}
max.delay <- 400
x <- correlateReads(bam.files, max.delay, param=discard.se.param)
plot(0:max.delay, x, type="l", ylab="CCF", xlab="Delay (bp)")
title("Cross Correlation Plot")
```


Coverage plot for choosing window size:


```{r, echo=FALSE}
collected <- list()

## Should parallelize ? 
for (curbam in bam.files) {
  windowed <- windowCounts(curbam, spacing=50, width=50, param=discard.se.param, filter=20, ext=0)
  rwsms <- rowSums(assay(windowed))
  maxed <- findMaxima(rowRanges(windowed), range=1000, metric=rwsms)
  collected[[curbam]] <- profileSites(curbam, rowRanges(windowed)[maxed],
                                      param=pe.param, weight=1/rwsms[maxed])
}

xranged <- as.integer(names(collected[[1]]))

for (i in seq(length(samples))){
  if (i ==1)
    plot(xranged, collected[[i]], type="l", col=i, lwd=1,
     xlim=c(-1000, 1000), ylim=c(0, 1.0), 
     xlab="Distance (bp)", ylab="Relative coverage per base")
  else
    lines(xranged, collected[[i]], col=i, lwd=1)
}

legend("topright", col=seq(length(samples)), samples, pch=16)
title("Coverage Profile")
abline(v=c(-150,150), col="gray", lty=3, lwd=4)
```


## Windowed read counts, Filtering, Normalization ##

Read extraction parameters:

```{r, echo=FALSE, comment=""}
discard.se.param
window.width <- 100
data <- windowCounts(bam.files, width = window.width, param = discard.se.param, ext=0)
kable(as.data.frame(data$totals, row.name=samples), caption="Total number of reads in each library")
binned <- windowCounts(bam.files, bin=TRUE, width=1000, param=discard.se.param, ext=0)
```

Keep only high abundance regions relative to a  global background.

```{r, echo=FALSE}
filter.stat <- filterWindows(data, background=binned, type="global")
keep <- filter.stat$filter > log2(3)

hist(filter.stat$back.abundances, xlab="Adjusted bin log-CPM", breaks=100, 
     main="", xlim=c(min(filter.stat$back.abundances), 0))
global.bg <- filter.stat$abundances - filter.stat$filter
abline(v=global.bg[1], col="red", lwd=2)
abline(v=global.bg[1]+log2(3), col="blue", lwd=2)
legend("topright", lwd=2, col=c('red', 'blue'), legend=c("Background", "Threshold"))

filtered.data <- data[keep,]
kable(as.data.frame(filtered.data$totals, row.name=samples), caption="Total number of reads post filtering.")
```


```{r, echo=FALSE}
Norm.factors <- normOffsets(binned)
kable(as.data.frame(Norm.factors, row.names=samples), caption="Normalizing factors")
```

## Differential Accessibility Testing ##

Let's see how the samples are clustered:

```{r, echo=FALSE}
## binned.2 <- windowCounts(bam.files, bin=TRUE, width=1000, param=pe.param)
bin.adjc <- cpm(asDGEList(binned), log=TRUE)
plotMDS(bin.adjc, labels=samples)
```


```{r, echo=FALSE}
y <- asDGEList(filtered.data, norm.factors=Norm.factors)
y <- estimateDisp(y, design)

par(mfrow=c(1,2))
o <- order(y$AveLogCPM)
plot(y$AveLogCPM[o], sqrt(y$trended.dispersion[o]), type="l", lwd=2,
     ylim=c(0,1), xlab="Average log2 CPM", ylab=("Biological coefficient of variation"))

fit <- glmQLFit(y, design, robust=TRUE)
plotQLDisp(fit)

results <- glmQLFTest(fit)
kable(topTags(results), caption="Top Tags")
```

### Multiple Testing Correction ###

```{r, echo=FALSE}
merged <- mergeWindows(rowRanges(filtered.data), tol=1000L)
## kable(merged$region, caption="Merged regions")
```


```{r, echo=FALSE}
tabcom <- combineTests(merged$id, results$table)
kable(head(tabcom), caption="Combined Tests")
## kable(summary(width(merged$region)))
```



## Session Info ##
```{r}
# Dump session info for versioning, debugging, CITATIONS (!), etc.
sessionInfo()

# Explicitly remind user: cite us and/or the various components of the pipeline!
message("Please do not forget to appropriately cite this work.")
citation("ATACseekeR")
citation("csaw")
citation("PWMEnrich")
citation("LOLA")
```



