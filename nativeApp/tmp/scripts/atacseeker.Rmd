---
title: "ATACseq Analysis Report"
author: "ATACseeker"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: html_document
---

```{r load_library, message=FALSE, warning=FALSE, echo=FALSE}
## CRAN
library(statmod)
library(locfit)
library(knitr)
library(parallel)
library(R2HTML)

## Bioconductor packages
library(csaw) 
library(edgeR)
library(rtracklayer)
library(Rsamtools)
library(Homo.sapiens)
library(LOLA) 

## Github package
library(ATACseeker)
```

```{r setup_out_scratch, message=FALSE, warning=FALSE, echo=FALSE}
## Defining Output and Scratch directories.
test = TRUE

source("parse_AppSession.R")
app_session_name = gsub('/','-', app_session_name)
base_dir = "/data/output/appresults"
dump_dir = "/data/scratch"
if(test){
    base_dir = "/Users/asifzubair/projects/atacseq_counts/nativeApp/data/output/appresults"
    dump_dir = "/Users/asifzubair/projects/atacseq_counts/nativeApp/data/scratch"
}

output_dir = file.path(base_dir, project_id, app_session_name)
cmd1 = paste0("mkdir -p ", "'", output_dir, "'")
system(cmd1)
if (!test){
    cmd2 = paste0("echo cp /atacseeker/scripts/atacseeker.html \\''", output_dir, "'\\' >> /atacseeker/scripts/atacseeker.sh")
    system(cmd2)
}
```

```{r setup_var_input, message=FALSE, warning=FALSE, echo = FALSE}
## Setting up Control and Compare variables and Input directory.
control.label = control
compare.label = comparison
control = controlName
compare = compareName

base_dir = "/data/input/appresults"
if(test){
    base_dir = "/Users/asifzubair/projects/atacseq_counts/nativeApp/data/input/appresults"
}

control.files = c()
for (f in seq(length(controlName))){
    fastq_dir = file.path(base_dir, controlID[f])
    bam.tmp = list.files(fastq_dir, "*bam$", full.names = TRUE)
    bam.dmp = file.path(dump_dir, basename(bam.tmp))

    if (!test){
        mcmapply(system, command = paste("cp", bam.tmp, dump_dir))
        mcmapply(system, command = paste("samtools index", bam.dmp))
    }
    
    control.files = c(control.files, bam.dmp)
}

compare.files = c()
for (f in seq(length(compareName))){
    fastq_dir = file.path(base_dir, compareID[f])
    bam.tmp = list.files(fastq_dir, "*bam$", full.names = TRUE)
    bam.dmp = file.path(dump_dir, basename(bam.tmp))
    
    if (!test){
        mcmapply(system, command = paste("cp", bam.tmp, dump_dir))
        mcmapply(system, command = paste("samtools index", bam.dmp))
    }

    compare.files = c(compare.files, bam.dmp)
}

samples = c(control, compare)
num_control = length(control)
num_compare = length(compare)
num_samples = length(samples)
bam.files = c(control.files, compare.files)
```

```{r mtDNA_analysis, message=FALSE, warning=FALSE, echo=FALSE}
## Mitochondrial assembly
if (do_mtdNA_analysis){
    system(paste("mkdir -p", file.path(dump_dir, "mtDNA_assembly")))
    command = paste("mkdir -p", file.path(dump_dir, "mtDNA_assembly", samples))
    tmp <- mcmapply(system, command = command)

    chrM.files = file.path(dump_dir, "mtDNA_assembly", samples, paste0("chrM.",samples,".bam"))
    chrM_command = paste("samtools view -h", bam.files, "\"chrM\" | samtools view -Sb - >", chrM.files)
    tmp <- mcmapply(system, command = chrM_command)
    tmp <- mcmapply(system, command = paste("bash assembleMTgenome.sh", chrM.files, ">", file.path(dump_dir, "mtDNA_assembly", samples, "mtDNA_analysis.log 2>&1")))

    cmd3 = paste0("mv ", file.path(dump_dir, "mtDNA_assembly")," '", output_dir, "'")
    system(cmd3)
}
```

## Workflow Description ##

We work with the App Result generated by the Illumina's <a href="https://basespace.illumina.com/apps/2686684/BWA-Aligner" target="_blank"> BWA Aligner</a>. It is recommended that quality checks, including marking PCR dupes, are done using the BWA App prior to pushing the aligned bam files through the ATACseeker. 

The bam files are piped through <a href="http://bioconductor.org/packages/release/bioc/html/csaw.html" target="_blank"> csaw </a> for a two-group comparison. 

QC metrics for the aligned reads are also computed and displayed. Fragment size and window length parameters are estimated. Thereafter, the libraries are normalised and filtering of windows is done to retain only high abundance windows. Finally, differential accessibility testing is done and corrrections for multiple testing are performed. 

The design matrix used for the two-sample comparison is provided below.

```{r design, echo=FALSE}
treatment = c(rep("N", length(control)), rep("Y",length(compare)))
design <- model.matrix(~treatment) 
colnames(design) <- c("Intercept", compare.label)
rownames(design) <- samples
kable(design, caption = "Design Matrix")
```

## QC Metrics ##

We use <a href="https://cran.r-project.org/web/packages/preseqR/index.html" target="_blank"> preseqR </a> to estimate library complexity. Library complexity gives an idea of how many unique moelcules have been caputured. 

```{r lib_complexity, message=FALSE, echo=TRUE, eval=FALSE}
# NOTE: This chunk is NOT evaluated.
firstBp <- 1
lastBp <- 249250621
chr1_5primeCuts <- lapply(bam.files[1:2], function(BAM) 
                          resize(extractReads(bam.file=BAM,
                                              region=GRanges("chr1", 
                                                             IRanges(firstBp,
                                                                     lastBp))),
                           1, fix="start"))
ests <- lapply(chr1_5primeCuts, getEsts)

# write all the complexity graphs for each library to file.
pdf(file.path(dump_dir, "library_complexity.pdf"))

for (i in seq(length(control.files))){
    plotComplexity(chr1_5primeCuts[[i]], ests=ests[[i]])
    legend("bottomright", legend = control[i], col = "red", pch = 18)
}

for (i in seq(length(compare.files))){
    t = length(control.files) + i
    plotComplexity(chr1_5primeCuts[[t]], ests=ests[[t]])
    legend("bottomright", legend = compare[i], col = "red", pch = 18)
}

dev.off()

cmd4 = paste0("mv ", file.path(dump_dir, "library_complexity.pdf")," '", output_dir, "'")
system(cmd4)
```

```{r read_param, echo=FALSE, message=FALSE, warning=FALSE}
## make sure the blacklist is for the same reference which was used for the alignment.
blacklist <- import("wgEncodeDacMapabilityConsensusExcludable.hg19.bed.gz", genome="hg19")
chroms <- paste0("chr", c(seq(22), "X", "Y"))
discard.se.param <- readParam(pe = "none", restrict = chroms, discard = blacklist, minq = 10, dedup = TRUE)
```

```{r chrM_tssVsNontss, echo=FALSE, message=FALSE, warning=FALSE, fig.width=20, fig.height=10}
par(mfrow=c(1,2))

command = paste("samtools view", bam.files, "| wc -l")
counts = mcmapply(system, command = command, intern = rep(TRUE, num_samples))
chrM_command = paste("samtools view", bam.files, "\"chrM\" | wc -l")
chrM_counts = mcmapply(system, command = chrM_command, intern = rep(TRUE, num_samples))
chrMvsOther = (strtoi(as.vector(chrM_counts))) / strtoi(as.vector(counts)) 
names(chrMvsOther) <- samples
ylim = 1.1*max(chrMvsOther)
    
barplot(chrMvsOther[1:num_control], col = "blue", xlim = c(0,1), width = 1/(num_control+1), main = control.label, ylab = "fraction - mtDNA reads", ylim = c(0, ylim), las=3, cex.names = 0.8)
barplot(chrMvsOther[num_control+1:num_samples], col = "red", xlim = c(0,1), width = 1/(num_compare+1), main = compare.label, ylim = c(0, ylim), las=3, cex.names = 0.8)

proms <- promoters(Homo.sapiens, upstream=2000, downstream=2000) # for hg19
# wincounts <- windowCounts(bam.files,  shift=4, bin=TRUE, param=discard.se.param)
wincounts <- windowCounts(bam.files, bin=TRUE, param=discard.se.param)

tssWindows <- queryHits(findOverlaps(wincounts, proms))
nonTssWindows <- setdiff(seq_len(nrow(wincounts)), tssWindows)

TSS.bamCounts <- colSums(assays(wincounts[tssWindows,])$counts)
nonTSS.bamCounts <- colSums(assays(wincounts[nonTssWindows,])$counts)
TSSvsNonTSS <- TSS.bamCounts / nonTSS.bamCounts # ideally > 10...
names(TSSvsNonTSS) <- samples
ylim = 1.1*max(TSSvsNonTSS)

barplot(TSSvsNonTSS[1:num_control], xlim = c(0,1), width = 1/(num_control + 1), las=3, col = "blue", ylab = "fraction - TSS vs Non-TSS Counts", ylim = c(0, ylim), main = control.label, cex.names = 0.8)
barplot(TSSvsNonTSS[num_control+1 : num_samples], xlim = c(0,1), width = 1/(num_compare+1), las=3, col= "red", ylim = c(0, ylim), main = compare.label, cex.names = 0.8)
```

If the input data is __paired-end__, fragment sizes in the control and comparison samples are plotted using csaw's `getPESizes` function. Some diagnostic metrics are also shown to assess data quality.  

```{r pe_metrics, echo=FALSE, fig.width=20, fig.height=10}
source("atacseeker.R")
if(testPairedEndBam(bam.files[1])){

    # use mcmapply(), but only if we haven't already...
    if (!file.exists("controlQC.rds")) {
        controlQC <- mcmapply(getQC, name=control, pe.bam=control.files, SIMPLIFY=F)
        if(test)
            saveRDS(controlQC, "controlQC.rds")
    } else { 
        controlQC <- readRDS("controlQC.rds")
    }

    if (!file.exists("compareQC.rds")) {
        compareQC <- mcmapply(getQC, name=compare, pe.bam=compare.files, SIMPLIFY=F)
        if(test)
            saveRDS(compareQC, file="compareQC.rds")  
    } else { 
        compareQC <- readRDS("compareQC.rds")
    }

    # side by side 
    par(mfrow=c(1,2))

    # plot fragment sizes for control samples
    frag.dists.control <- lapply(controlQC, `[[`, "frag.dist")
    qcPlot(frag.dists.control, control.label)

    # plot fragment sizes for comparison samples
    frag.dists.compare <- lapply(compareQC, `[[`, "frag.dist")
    qcPlot(frag.dists.compare, compare.label)

    # now dump a diagnostic table 
    combinedQC <- append(controlQC, compareQC)
    readqc <- as.data.frame(do.call(rbind, lapply(combinedQC, `[[`, "qc")))
    colnames(readqc) <- c("Sample", "Total Reads", "Mapped Reads", "Single Read", "Mate Unmapped", "Unoriented", "Inter Chromosomal", "Frag. Size > 400 bp")
    kable(readqc, caption="Quality metrics for PE reads", row.names=FALSE)
}
```

<!-- TODO: Add description for cross correlation plot -->

```{r cross_corr, echo=FALSE}
# one plot-per-window
par(mfrow=c(1,1))

max.delay <- 400
x <- correlateReads(bam.files, max.delay, param=discard.se.param)
plot(0:max.delay, x, type="l", ylab="CCF", xlab="Delay (bp)")
title("Cross Correlation Plot")
```

Coverage plot for choosing window size:

```{r cov_plot, echo=FALSE}
collected <- list()

## Should parallelize ? 
for (curbam in bam.files) {
##    windowed <- windowCounts(curbam, spacing=150, width=150, param=discard.se.param, filter=20, ext=1)
##    windowed <- windowCounts(curbam, ext=0, shift=4, bin=TRUE, param=discard.se.param)
    windowed <- windowCounts(curbam, spacing=150, width=150, param=discard.se.param, filter=20, ext=NA)
    rwsms <- rowSums(assay(windowed))
    maxed <- findMaxima(rowRanges(windowed), range=1000, metric=rwsms)
    collected[[curbam]] <- profileSites(curbam, rowRanges(windowed)[maxed], param=discard.se.param, weight=1/rwsms[maxed])
}

xranged <- as.integer(names(collected[[1]]))
for (i in seq(length(samples))){
  if (i==1)
    plot(xranged, collected[[i]], type="l", col=i, lwd=1,
     xlim=c(-1000, 1000), ylim=c(0, 1.0), 
     xlab="Distance (bp)", ylab="Relative coverage per base")
  else
    lines(xranged, collected[[i]], col=i, lwd=1)
}

legend("topright", col=seq(length(samples)), samples, pch=16)
title("Coverage Profile")
abline(v=c(-150,150), col="gray", lty=3, lwd=4)
```

## Windowed read counts, Filtering, Normalization ##

Read extraction parameters:

```{r read_extraction, echo=FALSE, comment=""}
discard.se.param
window.width <- 150
data <- windowCounts(bam.files, width = window.width, param = discard.se.param, ext=1)
binned <- windowCounts(bam.files, bin=TRUE, width=1000, param=discard.se.param)
```

### Filtering ###

Keep only high abundance regions relative to a  global background.

```{r filter_global, echo=FALSE}
filter.stat <- filterWindows(data, background=binned, type="global")
keep <- filter.stat$filter > log2(3)

# hist(filter.stat$back.abundances, xlab="Adjusted bin log-CPM", breaks=100, main="", xlim=c(min(filter.stat$back.abundances), 0))
hist(filter.stat$back.abundances, xlab="Adjusted bin log-CPM", breaks=50, main="")
global.bg <- filter.stat$abundances - filter.stat$filter
abline(v=global.bg[1], col="red", lwd=2)
abline(v=global.bg[1]+log2(3), col="blue", lwd=2)
legend("topright", lwd=2, col=c('red', 'blue'), legend=c("Background", "Threshold"))

kable(as.data.frame(colSums(assays(data)$counts), row.name=samples), caption="Total number of reads in each library", col.names = "total reads")

filtered.data <- data[keep,]
kable(as.data.frame(colSums(assays(filtered.data)$counts), row.name=samples), caption="Total number of reads post filtering.", col.names = "total reads")
```

### Normalization ###

We account for composition bias.

```{r normalization, echo=FALSE, fig.width=20, fig.height=10}
Norm.factors <- normOffsets(binned)
barplot(as.vector(Norm.factors), names.arg=samples, main = "Normalizing factors", col = c(rep("blue", length(control)), rep("red",length(compare))), cex.names = 0.8, width = 1/(num_samples + 1), las = 3)
```

## Differential Accessibility Testing ##

Let's see how the samples are clustered:

```{r cluster, echo=FALSE}
## binned.2 <- windowCounts(bam.files, bin=TRUE, width=1000, param=pe.param)
bin.adjc <- cpm(asDGEList(binned), log=TRUE)
color = c(rep("blue", length(control)), rep("red",length(compare)))
plotMDS(bin.adjc, labels=samples, col=color)
## add legend
```

```{r est_disp, echo=FALSE}
y <- asDGEList(filtered.data, norm.factors=Norm.factors)
y <- estimateDisp(y, design)

par(mfrow=c(1,2))
o <- order(y$AveLogCPM)
plot(y$AveLogCPM[o], sqrt(y$trended.dispersion[o]), type="l", lwd=2,
     ylim=c(0,max(y$AveLogCPM[o])), xlab="Average log2 CPM", ylab=("Biological coefficient of variation"))

fit <- glmQLFit(y, design, robust=TRUE)
plotQLDisp(fit)

results <- glmQLFTest(fit, contrast=c(0,1))
kable(as.data.frame(topTags(results)), caption="Top Tags", row.names = FALSE)
```

### Multiple Testing Correction ###

```{r multiple_test, echo=FALSE}
merged <- mergeWindows(rowRanges(filtered.data), tol=1000L)
## kable(merged$region, caption="Merged regions")
tabcom <- combineTests(merged$id, results$table)
kable(head(tabcom), caption="Combined Tests")
## kable(summary(width(merged$region)))
```

### Results ###

```{r results, echo=FALSE}
# annotated:
is.sig <- tabcom$FDR <= 0.05
anno <- detailRanges(merged$region, txdb=Homo.sapiens, orgdb=Homo.sapiens)
combined <- data.frame(as.data.frame(merged$region)[,1:3], tabcom, anno)
accRanges <- makeGRangesFromDataFrame(combined, keep=TRUE)
diffAccRanges <- accRanges[accRanges$FDR <= 0.1] 

# export to a BED file

# -log10(p) as bed file "score", could also export to bigWig
score(diffAccRanges) <- -1 * log10(diffAccRanges$PValue)

# Output sites as a BED file (post-FDR-correction, chop at 0.1 or 0.01?) 
export(diffAccRanges, file.path(dump_dir, "diffAccRanges.NS.fdrLt01.hg19.bed"))

cmd5 = paste0("mv ", file.path(dump_dir, "diffAccRanges.NS.fdrLt01.hg19.bed"), " '", output_dir, "'")
system(cmd5)

# print out the significant (FDR <= 0.1) results 
# kable(as(diffAccRanges, "data.frame"), caption="Significant Results")
HTML(as(diffAccRanges[diffAccRanges$logFC.up > 0,], "data.frame"), file=file.path(dump_dir, "diffAccRegions.logFC.UP.html"))
HTML(as(diffAccRanges[diffAccRanges$logFC.down > 0,], "data.frame"), file=file.path(dump_dir, "diffAccRegions.logFC.DOWN.html"))

write.table(as(diffAccRanges, "data.frame"), file.path(dump_dir, "diffAccRegions.tsv"), row.names=FALSE, sep="\t")

cmd6 = paste0("mv ", file.path(dump_dir, "diffAccRegions.logFC.*.html"), " '", output_dir, "'")
system(cmd6)
cmd7 = paste0("mv ", file.path(dump_dir, "diffAccRegions.tsv"), " '", output_dir, "'")
system(cmd7)
```

```{r bed_track_view, echo=FALSE}
accessByScore <- diffAccessible[rev(order(diffAccessible$score))]
plotRegion(accessByScore[1]) 
```

Regions containing windows which are more accessible are in `diffAccRegions.logFC.UP.html` and those with less accessible windows are in `diffAccRegions.logFC.DOWN.html`. A raw text file with all differentially accessible regions is written to output folder. A `bed` file containing differentially accessible regions has also been written to the output folder. The score column of the `bed` file indicates the negative-log of the p-value.


## LOLA ##

```{r lola, eval=FALSE, echo=TRUE}
# NOTE: This chunk is NOT evaluated.
# run LOLA? Yes!
dbPath <- system.file("extdata", "hg19", package="LOLA")
regionDB <- loadRegionDB(dbPath)
data("sample_input", package="LOLA") # load userSets
data("sample_universe", package="LOLA") # load userUniverse
if (FALSE) show(userUniverse)
locResults <- runLOLA(diffAccRanges, userUniverse, regionDB, cores=1)
kable(locResults[order(qValue),]) # this is just a demo, fix for app

if(FALSE) {
  # for later
  library(rtracklayer)
  CTCFsites <- import("ubiquitousCTCFsites.hg19.bed")
  repeatRegions <- import("repeatmasker.hg19.bed")

  # FIXME: use erma for this 
  hspcChromHMM <- import("CD34.chromImpute.hg19.bed")
}

# Motif enrichment (PWM-based, will re-use this for differential ChIP-seq app)
library(PWMEnrich)
library(PWMEnrich.Hsapiens.background)
library(BSgenome.Hsapiens.UCSC.hg19)
data(PWMLogn.hg19.MotifDb.Hsap)
seqs <- getSeq(Hsapiens, diffAccRanges)
res <- motifEnrichment(seqs, PWMLogn.hg19.MotifDb.Hsap)
saveRDS(res, file="motifEnrichmentNS.hg19.rds")

# Top 10 motifs by enrichment
kable(head(motifRankingForGroup(res), 10))
```

## Session Info ##

```{r sess_info, echo=FALSE, comment=""}
# Dump session info for versioning, debugging, CITATIONS (!), etc.
sessionInfo()
```

## References ##
```{r references, echo=FALSE, comment="", warning=FALSE}
# Explicitly remind user: cite us and/or the various components of the pipeline!
message("Please do not forget to appropriately cite this work.")
citation("preseqR")
citation("ATACseeker")
citation("csaw")
## citation("PWMEnrich")
citation("LOLA")
```
