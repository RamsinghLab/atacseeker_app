---
title: "ATACseq Analysis Report"
author: "ATACseeker"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: html_document
---


```{r, message=FALSE, warning=FALSE, echo=FALSE}
library(csaw) 
library(edgeR)
library(statmod)
library(locfit)
library(knitr)
```


```{r, message=FALSE, warning=FALSE, echo=FALSE}
source("parse_AppSession.R")

app_session_name = gsub('/','-', app_session_name)

base_dir = "/data/output/appresults"
## base_dir = "/Users/asifzubair/projects/atacseq_counts/nativeApp/data/output/appresults"

output_dir = file.path(base_dir, project_id, app_session_name)

cmd1 = paste0("mkdir -p ", "'", output_dir, "'")
system(cmd1)

cmd2 = paste0("echo cp /atacseeker/scripts/atacseeker.html \\''", output_dir, "'\\' >> /atacseeker/scripts/atacseeker.sh")
system(cmd2)
```


## Workflow Description ##

We work with the App Result generated by the Illumina BWA App. It is recommended that quality checks, including PCR dupes, is done using the BWA App prior to pushing the aligned bam files through the ATACseq App. 

The bam files are piped through [csaw](http://bioconductor.org/packages/release/bioc/html/csaw.html) for a two-group comparison. 

QC metrics for the aligned reads are also computed and displayed. Fragment size and window length parameters are estimated. Thereafter, the libraries are normalised and filtering of windows is done to retain only high abundance windows. Finally, differential accessibility testing is done and corrrections for multiple testing are performed. 


```{r, echo = FALSE}

## control.label = "Normal Cells"
## compare.label = "Senescent Cells"

control.label = control
compare.label = comparison

## fastq_dir="/Users/asifzubair/SkyDrive/projects/atacseq/data/fastq"

## control = c("normal1", "normal2", "normal4")
## compare = c("senescent1", "senescent2", "senescent4")

control = controlName
compare = compareName
  
## control.files = file.path(fastq_dir, paste0(control, ".unique_q10minimum_noChrM.hg19.sorted.bam"))
## compare.files = file.path(fastq_dir, paste0(compare, ".unique_q10minimum_noChrM.hg19.sorted.bam"))

base_dir = "/data/input/appresults"
## base_dir = "/Users/asifzubair/projects/atacseq_counts/nativeApp/data/input/appresults"

control.files = c()
for (f in seq(length(controlName))){
  
  fastq_dir = file.path(base_dir, controlID[f])
  control.files = c(control.files, file.path(fastq_dir, paste0(controlName[f], ".bam")))
  
  }

compare.files = c()
for (f in seq(length(compareName))){
  
  fastq_dir = file.path(base_dir, compareID[f])
  compare.files = c(compare.files, file.path(fastq_dir, paste0(compareName[f], ".bam")))
  
  }

samples = c(control, compare)
bam.files = c(control.files, compare.files)
```

The design matrix used for the two-sample comparison is provided below.

```{r, echo=FALSE}
treatment = c(rep("N", length(control)), rep("Y",length(compare)))

design <- model.matrix(~treatment) 
colnames(design) <- c("Intercept", compare.label)
rownames(design) <- samples

kable(design, caption = "Design Matrix")
```

## QC Metrics ##

```{r,echo=FALSE}
frag.len <- 150
## Do we use the minq=50 parameter ?
pe.first <- readParam(dedup=TRUE, pe="first")
pe.param <- readParam(max.frag = frag.len, pe = "both", dedup=TRUE)
```

Fragment sizes in the control and comparison samples are plotted using csaw's `getPESizes` function. 

```{r, echo=FALSE}
reads_qc = c()

for (i in seq(length(control))){

  pe.bam <- control.files[i]
  out <- getPESizes(pe.bam)
  frag.sizes <- out$sizes[out$sizes<=800]
  reads_qc = rbind(reads_qc, c(sample = control[i], out$diagnostics, too.large=sum(out$sizes > 400)))
  
  if (i ==1) {
    plot(density(frag.sizes), xlab="Fragment sizes (bp)", ylab="Density", main=control.label, ylim = c(0,0.015), col = i)
    abline(v=100, col="gray", lwd=4, lty=3)
    } else 
      lines(density(frag.sizes), col = i)
  }

legend("topright", legend = control, col = seq(length(control)), lwd = 1, bty = "n")

for (i in seq(length(compare))){
  pe.bam <- compare.files[i]
  out <- getPESizes(pe.bam)
  frag.sizes <- out$sizes[out$sizes<=800]
  reads_qc = rbind(reads_qc, c(sample = compare[i], out$diagnostics, too.large=sum(out$sizes > 400)))
  
  if (i ==1) {
    plot(density(frag.sizes), xlab="Fragment sizes (bp)", ylab="Density", main=compare.label, ylim = c(0,0.015), col = i)
    abline(v=100, col="gray", lwd=4, lty=3)
    } else
      lines(density(frag.sizes), col = i)
  }

legend("topright", legend = compare, col = seq(length(compare)), lwd = 1, bty = "n")

colnames(reads_qc) = c("Sample", "Total Reads", "Mapped Reads", "Single Read", "Mate Unmapped", "Unoriented", "Inter Chromosomal", "Frag. Size > 400 bp")
kable(reads_qc, caption="Quality metrics for PE reads")
```


<!-- TODO: Add description for cross correlation plot -->


```{r, echo=FALSE}
max.delay <- 400
x <- correlateReads(bam.files, max.delay, param=pe.first)
plot(0:max.delay, x, type="l", ylab="CCF", xlab="Delay (bp)")
title("Cross Correlation Plot")
```


Coverage plot for choosing window size:


```{r, echo=FALSE}
collected <- list()

for (curbam in bam.files) {
  windowed <- windowCounts(curbam, spacing=50, width=50, param=pe.param, filter=20)
  rwsms <- rowSums(assay(windowed))
  maxed <- findMaxima(rowRanges(windowed), range=1000, metric=rwsms)
  collected[[curbam]] <- profileSites(curbam, rowRanges(windowed)[maxed],
                                      param=pe.param, weight=1/rwsms[maxed])
}

xranged <- as.integer(names(collected[[1]]))

for (i in seq(length(samples))){
  if (i ==1)
    plot(xranged, collected[[i]], type="l", col=i, lwd=1,
     xlim=c(-1000, 1000), ylim=c(0, 1.0), 
     xlab="Distance (bp)", ylab="Relative coverage per base")
  else
    lines(xranged, collected[[i]], col=i, lwd=1)
}

legend("topright", col=seq(length(samples)), samples, pch=16)
title("Coverage Profile")
abline(v=c(-150,150), col="gray", lty=3, lwd=4)
```


## Windowed read counts, Filtering, Normalization ##

Read extraction parameters:

```{r, echo=FALSE, comment=""}
pe.param
window.width <- 75
data <- windowCounts(bam.files, width = window.width, param = pe.param)
kable(as.data.frame(data$totals, row.name=samples), caption="Total number of reads in each library")
binned <- windowCounts(bam.files, bin=TRUE, width=1000, param=pe.param)
```

Keep only high abundance regions according to a pre-defined threshold.

```{r, echo=FALSE}
filter.stat <- filterWindows(data, background=binned, type="global")
keep <- filter.stat$filter > log2(3)

hist(filter.stat$back.abundances, xlab="Adjusted bin log-CPM", breaks=100, 
     main="", xlim=c(min(filter.stat$back.abundances), 0))
global.bg <- filter.stat$abundances - filter.stat$filter
abline(v=global.bg[1], col="red", lwd=2)
abline(v=global.bg[1]+log2(3), col="blue", lwd=2)
legend("topright", lwd=2, col=c('red', 'blue'), legend=c("Background", "Threshold"))

filtered.data <- data[keep,]
kable(as.data.frame(filtered.data$totals, row.name=samples), caption="Total number of reads post filtering.")
```


```{r, echo=FALSE}
Norm.factors <- normOffsets(binned)
kable(as.data.frame(Norm.factors, row.names=samples), caption="Normalizing factors")
```

## Differential Accessibility Testing ##

Let's see how the samples are clustered:

```{r, echo=FALSE}
## binned.2 <- windowCounts(bam.files, bin=TRUE, width=1000, param=pe.param)
bin.adjc <- cpm(asDGEList(binned), log=TRUE)
plotMDS(bin.adjc, labels=samples)
```


```{r, echo=FALSE}
y <- asDGEList(filtered.data, norm.factors=Norm.factors)
y <- estimateDisp(y, design)

par(mfrow=c(1,2))
o <- order(y$AveLogCPM)
plot(y$AveLogCPM[o], sqrt(y$trended.dispersion[o]), type="l", lwd=2,
     ylim=c(0,1), xlab="Average log2 CPM", ylab=("Biological coefficient of variation"))

fit <- glmQLFit(y, design, robust=TRUE)
plotQLDisp(fit)

results <- glmQLFTest(fit)
kable(topTags(results), caption="Top Tags")
```

### Multiple Testing Correction ###

```{r, echo=FALSE}
merged <- mergeWindows(rowRanges(filtered.data), tol=1000L)
## kable(merged$region, caption="Merged regions")
```


```{r, echo=FALSE}
tabcom <- combineTests(merged$id, results$table)
kable(head(tabcom), caption="Combined Tests")
## kable(summary(width(merged$region)))
```

