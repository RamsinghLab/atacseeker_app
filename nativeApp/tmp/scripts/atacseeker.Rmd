---
title: "ATACseq Analysis Report"
author: "ATACseeker"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: html_document
---


```{r, message=FALSE, warning=FALSE, echo=FALSE}
library(csaw) 
library(edgeR)
library(statmod)
library(locfit)
library(knitr)
```


```{r, echo=FALSE}

source("parse_AppSession.R")

```


## Workflow Description ##


The raw reads are aligned to the hg19 assembly using [bwa](https://github.com/lh3/bwa). Quality checks are made and duplicate reads are removed using [samblaster](https://github.com/GregoryFaust/samblaster). The produced bam files are piped through [csaw](http://bioconductor.org/packages/release/bioc/html/csaw.html) for a two-group comparison. 

QC metrics for the aligned reads are computed. Fragment size and window length parameters are estimated. Thereafter, the libraries are normalised and filtering of windows is done to retain high abundance windows. Finally, differential accessibility testing is done and corrrections for multiple testing are performed. 


```{r, echo = FALSE}

##control.label = "Normal Cells"
##compare.label = "Senescent Cells"

control.label = control
compare.label = comparison

fastq_dir="/Users/asifzubair/SkyDrive/projects/atacseq/data/fastq"

##control = c("normal1", "normal2", "normal4")
##compare = c("senescent1", "senescent2", "senescent4")

control = controlName
compare = compareName
  
control.files = file.path(fastq_dir, paste0(control, ".unique_q10minimum_noChrM.hg19.sorted.bam"))
compare.files = file.path(fastq_dir, paste0(compare, ".unique_q10minimum_noChrM.hg19.sorted.bam"))

samples = c(control, compare)
bam.files = file.path(fastq_dir, paste0(samples, ".unique_q10minimum_noChrM.hg19.sorted.bam"))
```

The design matrix used for the two-sample comparison is provided below.

```{r, echo=FALSE}
treatment = c(rep("N", length(control)), rep("Y",length(compare)))

design <- model.matrix(~treatment) 
colnames(design) <- c("Intercept", compare.label)
rownames(design) <- samples

kable(design, caption = "Design Matrix")
```

## QC Metrics ##

```{r,echo=FALSE}
frag.len <- 150
# Do we use the minq=50 parameter ?
pe.first <- readParam(dedup=TRUE, pe="first")
pe.param <- readParam(max.frag = frag.len, pe = "both", dedup=TRUE)
```

Fragment sizes in the control and comparison samples are plotted using csaw's `getPESizes` function. 

```{r, echo=FALSE}
reads_qc = c()

for (i in seq(length(control))){

  pe.bam <- control.files[i]
  out <- getPESizes(pe.bam)
  frag.sizes <- out$sizes[out$sizes<=800]
  reads_qc = rbind(reads_qc, c(sample = control[i], out$diagnostics, too.large=sum(out$sizes > 400)))
  
  if (i ==1) {
    plot(density(frag.sizes), xlab="Fragment sizes (bp)", ylab="Density", main=control.label, ylim = c(0,0.015), col = i)
    abline(v=100, col="gray", lwd=4, lty=3)
    } else 
      lines(density(frag.sizes), col = i)
  }

legend("topright", legend = control, col = seq(length(control)), lwd = 1, bty = "n")

for (i in seq(length(compare))){
  pe.bam <- compare.files[i]
  out <- getPESizes(pe.bam)
  frag.sizes <- out$sizes[out$sizes<=800]
  reads_qc = rbind(reads_qc, c(sample = compare[i], out$diagnostics, too.large=sum(out$sizes > 400)))
  
  if (i ==1) {
    plot(density(frag.sizes), xlab="Fragment sizes (bp)", ylab="Density", main=compare.label, ylim = c(0,0.015), col = i)
    abline(v=100, col="gray", lwd=4, lty=3)
    } else
      lines(density(frag.sizes), col = i)
  }

legend("topright", legend = compare, col = seq(length(compare)), lwd = 1, bty = "n")

colnames(reads_qc) = c("Sample", "Total Reads", "Single Read", "Mate Unmapped", "Unoriented", "Inter chromosomal", "Frag. Size > 400 bp")
kable(reads_qc, caption="Quality metrics for PE reads")
```


<!-- TODO: Add description for cross correlation plot -->


```{r, echo=FALSE}
max.delay <- 400
x <- correlateReads(bam.files, max.delay, param=pe.first)
plot(0:max.delay, x, type="l", ylab="CCF", xlab="Delay (bp)")
title("Cross Correlation Plot")
```


Coverage plot for choosing window size:


```{r, echo=FALSE}
collected <- list()

for (curbam in bam.files) {
  windowed <- windowCounts(curbam, spacing=50, width=50, param=pe.param, filter=20)
  rwsms <- rowSums(assay(windowed))
  maxed <- findMaxima(rowRanges(windowed), range=1000, metric=rwsms)
  collected[[curbam]] <- profileSites(curbam, rowRanges(windowed)[maxed],
                                      param=pe.param, weight=1/rwsms[maxed])
}

xranged <- as.integer(names(collected[[1]]))

for (i in seq(length(samples))){
  if (i ==1)
    plot(xranged, collected[[i]], type="l", col=i, lwd=1,
     xlim=c(-1000, 1000), ylim=c(0, 1.0), 
     xlab="Distance (bp)", ylab="Relative coverage per base")
  else
    lines(xranged, collected[[i]], col=i, lwd=1)
}

legend("topright", col=seq(length(samples)), samples, pch=16)
title("Coverage Profile")
abline(v=c(-150,150), col="gray", lty=3, lwd=4)
```


## Windowed read counts, Filtering, Normalization ##

Read extraction parameters:

```{r, echo=FALSE, comment=""}
pe.param
window.width <- 75
data <- windowCounts(bam.files, width = window.width, param = pe.param)
kable(as.data.frame(data$totals, row.name=samples), caption="Total number of reads in each library")
binned <- windowCounts(bam.files, bin=TRUE, width=1000, param=pe.param)
```

Keep only high abundance regions according to a pre-defined threshold.

```{r, echo=FALSE}
filter.stat <- filterWindows(data, background=binned, type="global")
keep <- filter.stat$filter > log2(3)

hist(filter.stat$back.abundances, xlab="Adjusted bin log-CPM", breaks=100, 
     main="", xlim=c(min(filter.stat$back.abundances), 0))
global.bg <- filter.stat$abundances - filter.stat$filter
abline(v=global.bg[1], col="red", lwd=2)
abline(v=global.bg[1]+log2(3), col="blue", lwd=2)
legend("topright", lwd=2, col=c('red', 'blue'), legend=c("Background", "Threshold"))

filtered.data <- data[keep,]
kable(as.data.frame(filtered.data$totals, row.name=samples), caption="Total number of reads post filtering.")
```


```{r, echo=FALSE}
Norm.factors <- normalize(binned)
kable(as.data.frame(Norm.factors, row.names=samples), caption="Normalizing factors")
```

## Differential Accessibility Testing ##

Let's see how the samples are clustered:

```{r, echo=FALSE}
#binned.2 <- windowCounts(bam.files, bin=TRUE, width=1000, param=pe.param)
bin.adjc <- cpm(asDGEList(binned), log=TRUE)
plotMDS(bin.adjc, labels=samples)
```


```{r, echo=FALSE}
y <- asDGEList(filtered.data, norm.factors=Norm.factors)
y <- estimateDisp(y, design)

par(mfrow=c(1,2))
o <- order(y$AveLogCPM)
plot(y$AveLogCPM[o], sqrt(y$trended.dispersion[o]), type="l", lwd=2,
     ylim=c(0,1), xlab="Average log2 CPM", lab=("Biological coefficient of variation"))

fit <- glmQLFit(y, design, robust=TRUE)
plotQLDisp(fit)

results <- glmQLFTest(fit)
kable(topTags(results), caption="Top Tags")
```

### Multiple Testing Correction ###

```{r, echo=FALSE}
merged <- mergeWindows(rowRanges(filtered.data), tol=1000L)
kable(merged$region, caption="Merged regions")
```


```{r, echo=FALSE}
tabcom <- combineTests(merge$id, results$table)
kable(head(tabcom), caption="Combined Tests")
kable(summary(width(merged$region)))
```

