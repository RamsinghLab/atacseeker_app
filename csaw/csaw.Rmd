---
title: "csaw"
author: "asif zubair"
date: "June 1, 2015"
output: html_document
---

**Note:** This document summarizes the csaw workflow and borrows heavily from the userguide. 

Loading required libraries. `csaw` is based on `edgeR`. `statmod` was required for one of the functions used below.

```{r, message=FALSE, warning=FALSE}
require(csaw) 
require(edgeR) 
require(statmod)
```

Specify the bam files and create design matrix based on our experiment.

```{r}
bam.files <- c("normal1_sorted_filtered.bam", "normal2_sorted_filtered.bam", 
               "normal4_sorted_filtered.bam", 
               "senescent1_sorted_filtered.bam", "senescent2_sorted_filtered.bam", 
               "senescent4_sorted_filtered.bam") 

subject = factor(rep(c(1,2,3), 2))
treatment = c(rep("N", 3), rep("S",3))

design <- model.matrix(~subject + treatment) 
colnames(design) <- c("intercept", "subject-2","subject-3","senescent")
```
# Reads to Counts #

### Deciding window size ###

`windowCounts` function will use a sliding window approach to count fragments for a set of libraries. The number of fragments
overlapping a genomic window is counted. This is repeated after sliding the window along the genome to a new position. A count is then obtained for each window in each library.

For ascertaining window size, quoting directly **from the user guide**: 

"The window size can be interpreted as a measure of the width of the binding site. Thus, TF analyses will typically use a small window size, e.g., 10 - 20 bp. This maximizes spatial resolution to allow optimal detection of narrow regions of enrichment. For histone marks, widths of at least 150 bp are recommended [Humburg et al., 2011]. This corresponds to the length of DNA wrapped up in each nucleosome, i.e., the smallest relevant unit for histone mark enrichment."

### Filtering low-quality reads ###

Read extraction from the BAM files is controlled with the `param` argument in `windowCounts`. 

The param argument expects a `readParam()` object. Typically, one would define different `readParam()` objects with varying strictness and use them later on in the analysis. 

```{r}
default.param <- readParam()
default.param
strict.param <- readParam(minq=50, dedup=TRUE)
strict.param
```

### Avoiding problematic regions ###

One can avoid known/inferred problematic regions on the genome by specifying them in `restrict`. These could be regions that may be known to be problematic as described in the [link](https://sites.google.com/site/anshulkundaje/projects/blacklists), or discovered using *RepeatMasker*. The `restrict` argument could also be used as a way of doing the analysis one chromosome at a time on huge datasets or in limted memory. 

A possible usage is shown below:

```{r}
new.param <- readParam(discard=repeats, restrict=c("chr1", "chr10", "chrX"))
```

### Paired-end data ###

We move forward to the actual `windowCounts` call for paired end data. This can be accounted for by setting `pe="both"` in the `param` object. By default, only proper pairs are used whereby the two reads are on the same chromosome, face inward and are no more than `max.frag` apart.

The returned object, here `data`, is a `SummarizedExperiment` object. For future reference, `assay` can be used to obtain the matrix of counts. The coordinates of each window are stored in the `rowRanges`. The total number of reads in each library are stored as `totals` in the `colData`. 

```{r}
frag.len <- 400
window.width <- 150
pe.param <- readParam(max.frag = frag.len, pe = "both")
data <- windowCounts(bam.files, width = window.width, param = pe.param)
data$totals
```

### Estimating `max.frag` value ###

A suitable value of `max.frag` can be chosen by examining the distribution of fragment sizes using the `getPESizes` function.

```{r}
pe.bam <- "normal1_sorted_filtered.bam"
out <- getPESizes(pe.bam)
frag.sizes <- out$sizes[out$sizes<=800]
hist(frag.sizes, breaks=50, xlab="Fragment sizes (bp)", ylab="Frequency", main="")
abline(v=400, col="red")
```

The number of fragments exceeding the maximum size can be recorded for quality control. The `getPESizes` function also returns the number of single reads, pairs with one unmapped read, improperly orientated pairs and inter-chromosomal pairs. A non-negligble proportion of these reads may be indicative of problems with paired-end alignment or sequencing. 

```{r}
c(out$diagnostics, too.large=sum(out$sizes > 400))
```

In datasets where many read pairs are invalid, the reads in those pairs can be rescued by setting `rescue.ext` to a positive integer.

### Estimating the average fragment length ###
  
**Cross-correlation plots**
Cross-correlation plots can be generated directly from BAM ﬁles using the `correlateReads` function. Efficient IP should yield a smooth peak at a delay distance corresponding to the average fragment length. The location of the peak can then be used as an estimate of the fragment length for read extension in `windowCounts`. 

Cross-correlation plots can be used for fragment length estimation of narrow histone marks such as histone acetylation and H3K4 methylation. However, they are less effective for regions of diffuse enrichment where bimodality is not obvious (e.g., H3K27 trimethylation).

```{r}
n <- 1000 
dedup.on <- readParam(dedup=TRUE) 
pe.corr <- correlateReads(pe.bam, n, param=dedup.on) 
plot(0:n, pe.corr, col="blue", ylim=c(0, 0.1), xlim=c(0, 1000), 
                              xlab="Delay (bp)", ylab="CCF", pch=16, type="l", lwd=2) 
```

### Choice of Window Size ###

The coverage proﬁle around potential binding sites can be obtained with the profileSites function. Here, the binding sites are deﬁned by taking high-abundance 50 bp windows and identifying those that are locally maximal using findMaxima. For each selected window, profileSites records the coverage across the ﬂanking regions as a function of the distance from the edge of the window. This is divided by the count for the window itself to obtain a relative coverage, based on the speciﬁcation of weight. The values are then averaged across all windows to obtain an aggregated coverage proﬁle for each library.

```{r}
bam.files <- c("normal1_sorted_filtered.bam", "normal2_sorted_filtered.bam", 
               "normal4_sorted_filtered.bam", 
               "senescent1_sorted_filtered.bam", "senescent2_sorted_filtered.bam", 
               "senescent4_sorted_filtered.bam")

collected <- list()

for (curbam in bam.files) {
  windowed <- windowCounts(curbam, spacing=50, width=50, param=dedup.on, filter=20)
  rwsms <- rowSums(assay(windowed))
  maxed <- findMaxima(rowRanges(windowed), range=1000, metric=rwsms)
  collected[[curbam]] <- profileSites(curbam, rowRanges(windowed)[maxed],
  param=dedup.on, weight=1/rwsms[maxed])
}

xranged <- as.integer(names(collected[[1]]))
plot(xranged, collected[[1]], type="l", col="blue", xlim=c(-1000, 1000), lwd=2,
xlab="Distance (bp)", ylab="Relative coverage per base")
lines(xranged, collected[[2]], col="forestgreen", lwd=2)
lines(xranged, collected[[3]], col=rgb(0,0,0,0.5), lwd=2)
legend("topright", col=c("blue", "forestgreen", rgb(0,0,0,0.5)), c("normal1_sorted_filtered", 
                  "normal2_sorted_filtered", "normal4_sorted_filtered", 
                  "senescent1_sorted_filtered", "senescent2_sorted_filtered", 
                  "senescent4_sorted_filtered.bam"), pch=16)
abline(v=c(-150,200), col="dodgerblue", lty=2)
```
# Filtering uninteresting windows #

```{r}
keep <- aveLogCPM(asDGEList(data)) >= -1 
data <- data[keep,]
binned <- windowCounts(bam.files, bin=TRUE, width=10000) 
normfacs <- normalize(binned)
```

```{r}
y <- asDGEList(data, norm.factors=normfacs) 
y <- estimateDisp(y, design) 
fit <- glmQLFit(y, design, robust=TRUE) 
results <- glmQLFTest(fit)
```

```{r}
merged <- mergeWindows(rowData(data), tol=1000L) 
tabcom <- combineTests(merged$id, results$table)
```




