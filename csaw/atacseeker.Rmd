---
title: "ATACseq Analysis Report"
author: "ATACseeker"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: html_document
---
  


<!-- TODO: Give brief description of the pipeline and workflow -->




```{r, message=FALSE, warning=FALSE, echo=FALSE}
library(csaw) 
library(edgeR)
library(statmod)
library(locfit)
library(knitr)
```


```{r, echo = FALSE}
control.label = "Normal Cells"
compare.label = "Senescent Cells"

fastq_dir="/Users/asifzubair/SkyDrive/projects/atacseq/data/fastq"

control = c("normal1", "normal2", "normal4")
compare = c("senescent1", "senescent2", "senescent4")

control.files = file.path(fastq_dir, paste0(control, ".unique_q10minimum_noChrM.hg19.sorted.bam"))
compare.files = file.path(fastq_dir, paste0(compare, ".unique_q10minimum_noChrM.hg19.sorted.bam"))

samples = c(control, compare)
bam.files = file.path(fastq_dir, paste0(samples, ".unique_q10minimum_noChrM.hg19.sorted.bam"))
```

We construct the design matrix based on sample labels.

```{r, echo=FALSE}
treatment = c(rep("N", length(control)), rep("Y",length(compare)))

design <- model.matrix(~treatment) 
colnames(design) <- c("Intercept", compare.label)
rownames(design) <- samples

kable(design, caption = "Design Matrix")
```

## QC Metrics ##

```{r,echo=FALSE}
frag.len <- 150
# Do we use the minq=50 parameter ?
pe.first <- readParam(dedup=TRUE, pe="first")
pe.param <- readParam(max.frag = frag.len, pe = "both", dedup=TRUE)
```

Diagnostic plots for fragment sizes:

```{r, echo=FALSE}
reads_qc = c()

for (i in seq(length(control))){

  pe.bam <- control.files[i]
  out <- getPESizes(pe.bam)
  frag.sizes <- out$sizes[out$sizes<=800]
  reads_qc = rbind(reads_qc, c(sample = control[i], out$diagnostics, too.large=sum(out$sizes > 400)))
  
  if (i ==1) {
    plot(density(frag.sizes), xlab="Fragment sizes (bp)", ylab="Density", main=control.label, ylim = c(0,0.015), col = i)
    abline(v=100, col="gray", lwd=4, lty=3)
    } else 
      lines(density(frag.sizes), col = i)
  }

legend("topright", legend = control, col = seq(length(control)), lwd = 1, bty = "n")

for (i in seq(length(compare))){
  pe.bam <- compare.files[i]
  out <- getPESizes(pe.bam)
  frag.sizes <- out$sizes[out$sizes<=800]
  reads_qc = rbind(reads_qc, c(sample = compare[i], out$diagnostics, too.large=sum(out$sizes > 400)))
  
  if (i ==1) {
    plot(density(frag.sizes), xlab="Fragment sizes (bp)", ylab="Density", main=compare.label, ylim = c(0,0.015), col = i)
    abline(v=100, col="gray", lwd=4, lty=3)
    } else
      lines(density(frag.sizes), col = i)
  }

legend("topright", legend = compare, col = seq(length(compare)), lwd = 1, bty = "n")

colnames(reads_qc) = c("Sample", "Total Reads", "Single Read", "Mate Unmapped", "Unoriented", "Inter chromosomal", "Frag. Size > 400 bp")
kable(reads_qc, caption="Quality metrics for PE reads")
```


<!-- TODO: Add description for cross correlation plot -->


```{r, echo=FALSE}
max.delay <- 400
x <- correlateReads(bam.files, max.delay, param=pe.first)
plot(0:max.delay, x, type="l", ylab="CCF", xlab="Delay (bp)")
title("Cross Correlation Plot")
```


Coverage plot for choosing winodw size:


```{r, echo=FALSE}
collected <- list()

for (curbam in bam.files) {
  windowed <- windowCounts(curbam, spacing=50, width=50, param=pe.param, filter=20)
  rwsms <- rowSums(assay(windowed))
  maxed <- findMaxima(rowRanges(windowed), range=1000, metric=rwsms)
  collected[[curbam]] <- profileSites(curbam, rowRanges(windowed)[maxed],
                                      param=pe.param, weight=1/rwsms[maxed])
}

xranged <- as.integer(names(collected[[1]]))

for (i in seq(length(samples))){
  if (i ==1)
    plot(xranged, collected[[i]], type="l", col=i, lwd=1,
     xlim=c(-1000, 1000), ylim=c(0, 1.0), 
     xlab="Distance (bp)", ylab="Relative coverage per base")
  else
    lines(xranged, collected[[i]], col=i, lwd=1)
}

legend("topright", col=seq(length(samples)), samples, pch=16)
title("Coverage Profile")
abline(v=c(-150,150), col="gray", lty=3, lwd=4)
```


## Windowed read counts, Filtering, Normalization ##

Read extraction parameters:

```{r, echo=FALSE, comment=""}
pe.param
window.width <- 75
data <- windowCounts(bam.files, width = window.width, param = pe.param)
kable(as.data.frame(data$totals, row.name=samples), caption="Total number of reads in each library")
```

Keep only high abundance regions according to a pre-defined threshold.

```{r, echo=FALSE}
abundance <- aveLogCPM(asDGEList(data))
keep <- abundance > -1
original <- data
data <- data[keep,]
kable(as.data.frame(data$totals, row.name=samples), caption="Total number of reads post filtering.")
```


```{r, echo=FALSE}
param<- readParam()
binned <- windowCounts(bam.files, bin=TRUE, width=1000, param=pe.param)
Norm.factors <- normalize(binned)
kable(as.data.frame(Norm.factors, row.names=samples), caption="Normalizing factors")
```

## Differential Accessibility Testing ##

Let's see how the samples are clustered:

```{r, echo=FALSE}
#binned.2 <- windowCounts(bam.files, bin=TRUE, width=1000, param=pe.param)
bin.adjc <- cpm(asDGEList(binned), log=TRUE)
plotMDS(bin.adjc, labels=samples)
```


```{r}
y <- asDGEList(data, norm.factors=Norm.factors)
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)
results <- glmQLFTest(fit)
kable(topTags(results))
```

### Multiple Testing Correction ###
