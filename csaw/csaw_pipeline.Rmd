---
title: "csaw pipeline"
author: "asif zubair"
date: "August 10, 2015"
output: html_document
---

**Summary**: This document will do an end to end `csaw` analysis on the bam files produced by the alignment pipeline. 

```{r, message=FALSE, warning=FALSE, echo=FALSE}
require(csaw) 
require(edgeR)
require(statmod)
require(locfit)
```


### Counting reads in windows ###


```{r, echo = FALSE}
fastq_dir="/Users/asifzubair/SkyDrive/projects/atacseq/data/fastq"
samples = c("normal1", "normal2", "normal4", "senescent1", "senescent2", "senescent4")
bam.files = file.path(fastq_dir, paste0(samples, ".unique_q10minimum_noChrM.hg19.sorted.bam"))
```


Let's look at the design matrix: 


```{r}
subject = factor(rep(c(1,2,3), 2))
treatment = c(rep("N", 3), rep("S",3))

design <- model.matrix(~subject + treatment) 
colnames(design) <- c("intercept", "subject2","subject3","senescent")
rownames(design) <- samples
design
```


A diagnostic plot for the fragment sizes for sample `normal1`.


```{r, echo=FALSE}
pe.bam <- bam.files[1]
out <- getPESizes(pe.bam)
frag.sizes <- out$sizes[out$sizes<=800]
hist(frag.sizes, breaks=50, xlab="Fragment sizes (bp)", ylab="Frequency", main="")
abline(v=400, col="red")

```


Some QC metrics for the same sample, `normal1`.


```{r, echo=FALSE}
c(out$diagnostics, too.large=sum(out$sizes > 400))
```


Cross-correlation plot:


```{r, echo=FALSE}
max.delay <- 500
dedup.on <- readParam(dedup=TRUE, minq=50)
x <- correlateReads(bam.files, max.delay, param=dedup.on)
plot(0:max.delay, x, type="l", ylab="CCF", xlab="Delay (bp)")
```


Coverage plot for choosing winodw size :


```{r, echo=FALSE}
# Specify the readParam object
dedup.on <- readParam(dedup=TRUE, minq=50) 
collected <- list()

for (curbam in bam.files) {
  windowed <- windowCounts(curbam, spacing=50, width=50, param=dedup.on, filter=20)
  rwsms <- rowSums(assay(windowed))
  maxed <- findMaxima(rowRanges(windowed), range=1000, metric=rwsms)
  collected[[curbam]] <- profileSites(curbam, rowRanges(windowed)[maxed],
  param=dedup.on, weight=1/rwsms[maxed])
}

xranged <- as.integer(names(collected[[1]]))
plot(xranged, collected[[1]], type="l", col=1, xlim=c(-1000, 1000), lwd=2,
xlab="Distance (bp)", ylab="Relative coverage per base")
lines(xranged, collected[[2]], col=2, lwd=2)
lines(xranged, collected[[3]], col=3, lwd=2)
lines(xranged, collected[[4]], col=4, lwd=2)
lines(xranged, collected[[5]], col=5, lwd=2)
lines(xranged, collected[[6]], col=6, lwd=2)
legend("topright", col=c(1:6), samples, pch=16)
title("coverage profile around potential binding sites")
abline(v=c(-100,150), col="dodgerblue", lty=2, lwd=4)
```


Finally, couting reads by windows :


```{r}
frag.len <- 400
window.width <- 150
pe.param <- readParam(max.frag = frag.len, pe = "both")
data <- windowCounts(bam.files, width = window.width, param = pe.param)
data$totals
```


### Normalization factors ###


```{r}
param<- readParam()
binned <- windowCounts(bam.files, bin=TRUE, width=10000, param=param)
normfacs <- normalize(binned)
normfacs
```

Do an MA plot : 

```{r, echo = FALSE}
adj.counts <- cpm(asDGEList(binned), log=TRUE)
cur.x <- adj.counts[,1]
cur.y <- adj.counts[,2]
smoothScatter(x=(cur.x+cur.y)/2+6*log2(10), y=cur.x-cur.y,
  xlab="A", ylab="M", main="1 vs 2")
all.dist <- diff(log2(normfacs[c(2, 1)]))
abline(h=all.dist, col="red")
```


### Filtering out low abundance regions ###

Keep only high abundance regions according to a pre-defined threshold.

```{r}
abundance <- aveLogCPM(asDGEList(data))
keep <- abundance > -1
original <- data
data <- data[keep,]
```



### Testing for Differential Binding ###

Let's see how the samples are clustered:

```{r, echo=FALSE}
binned.2 <- windowCounts(bam.files, bin=TRUE, width=2000, param=param)
bin.adjc <- cpm(asDGEList(binned.2), log=TRUE)
plotMDS(bin.adjc, labels=samples)
```


```{r}
y <- asDGEList(data, norm.factors=normfacs)
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)
#contrast <- makeContrasts(es - tn, levels=design)
#results <- glmQLFTest(fit, contrast=contrast)
```


